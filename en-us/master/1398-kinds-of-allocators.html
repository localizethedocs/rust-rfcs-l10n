<!DOCTYPE HTML>
<html lang="en_US" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>1398-kinds-of-allocators - The Rust RFC Book</title>


        <!-- Custom HTML head -->
        <script type="text/javascript" src="ltd-provenance.js"></script>
        <script type="text/javascript" src="ltd-current.js"></script>
        <script type="text/javascript" src="../../ltd-config.js"></script>
        <script type="text/javascript" src="../../ltd-flyout.js"></script>

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon-de23e50b.svg">
        <link rel="shortcut icon" href="favicon-8114d1fc.png">
        <link rel="stylesheet" href="css/variables-8adf115d.css">
        <link rel="stylesheet" href="css/general-2459343d.css">
        <link rel="stylesheet" href="css/chrome-ae938929.css">
        <link rel="stylesheet" href="css/print-9e4910d8.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="fonts/fonts-9644e21d.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="mdbook-highlight-css" href="highlight-493f70e1.css">
        <link rel="stylesheet" id="mdbook-tomorrow-night-css" href="tomorrow-night-4c0ae647.css">
        <link rel="stylesheet" id="mdbook-ayu-highlight-css" href="ayu-highlight-3fdfc3ac.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex-0060737d.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc-5025baa3.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="mdbook-body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="mdbook-sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("mdbook-sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="mdbook-sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="mdbook-sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="mdbook-page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="mdbook-menu-bar-hover-placeholder"></div>
                <div id="mdbook-menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="mdbook-sidebar-toggle" class="icon-button" for="mdbook-sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="mdbook-sidebar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg></span>
                        </label>
                        <button id="mdbook-theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="mdbook-theme-list">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M371.3 367.1c27.3-3.9 51.9-19.4 67.2-42.9L600.2 74.1c12.6-19.5 9.4-45.3-7.6-61.2S549.7-4.4 531.1 9.6L294.4 187.2c-24 18-38.2 46.1-38.4 76.1L371.3 367.1zm-19.6 25.4l-116-104.4C175.9 290.3 128 339.6 128 400c0 3.9 .2 7.8 .6 11.6c1.8 17.5-10.2 36.4-27.8 36.4H96c-17.7 0-32 14.3-32 32s14.3 32 32 32H240c61.9 0 112-50.1 112-112c0-2.5-.1-5-.2-7.5z"/></svg></span>
                        </button>
                        <ul id="mdbook-theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-ayu">Ayu</button></li>
                        </ul>
                        <button id="mdbook-search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="mdbook-searchbar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352c79.5 0 144-64.5 144-144s-64.5-144-144-144S64 128.5 64 208s64.5 144 144 144z"/></svg></span>
                        </button>
                    </div>

                    <h1 class="menu-title">The Rust RFC Book</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <span class=fa-svg id="print-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M128 0C92.7 0 64 28.7 64 64v96h64V64H354.7L384 93.3V160h64V93.3c0-17-6.7-33.3-18.7-45.3L400 18.7C388 6.7 371.7 0 354.7 0H128zM384 352v32 64H128V384 368 352H384zm64 32h32c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64v96c0 17.7 14.3 32 32 32H64v64c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V384zm-16-88c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg></span>
                        </a>
                        <a href="https://github.com/rust-lang/rfcs" title="Git repository" aria-label="Git repository">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span>
                        </a>

                    </div>
                </div>

                <div id="mdbook-search-wrapper" class="hidden">
                    <form id="mdbook-searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="mdbook-searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="mdbook-searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <span class=fa-svg id="fa-spin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M304 48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zm0 416c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM48 304c26.5 0 48-21.5 48-48s-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48zm464-48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM142.9 437c18.7-18.7 18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zm0-294.2c18.7-18.7 18.7-49.1 0-67.9S93.7 56.2 75 75s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zM369.1 437c18.7 18.7 49.1 18.7 67.9 0s18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9z"/></svg></span>
                            </div>
                        </div>
                    </form>
                    <div id="mdbook-searchresults-outer" class="searchresults-outer hidden">
                        <div id="mdbook-searchresults-header" class="searchresults-header"></div>
                        <ul id="mdbook-searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('mdbook-sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('mdbook-sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#mdbook-sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="mdbook-content" class="content">
                    <main>
                        <ul>
<li>Feature Name: allocator_api</li>
<li>Start Date: 2015-12-01</li>
<li>RFC PR: <a href="https://github.com/rust-lang/rfcs/pull/1398">rust-lang/rfcs#1398</a></li>
<li>Rust Issue: <a href="https://github.com/rust-lang/rust/issues/32838">rust-lang/rust#32838</a></li>
</ul>
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<p>Add a standard allocator interface and support for user-defined
allocators, with the following goals:</p>
<ol>
<li>
<p>Allow libraries (in libstd and elsewhere) to be generic with
respect to the particular allocator, to support distinct,
stateful, per-container allocators.</p>
</li>
<li>
<p>Require clients to supply metadata (such as block size and
alignment) at the allocation and deallocation sites, to ensure
hot-paths are as efficient as possible.</p>
</li>
<li>
<p>Provide high-level abstraction over the layout of an object in
memory.</p>
</li>
</ol>
<p>Regarding GC: We plan to allow future allocators to integrate
themselves with a standardized reflective GC interface, but leave
specification of such integration for a later RFC. (The design
describes a way to add such a feature in the future while ensuring
that clients do not accidentally opt-in and risk unsound behavior.)</p>
<h2 id="motivation"><a class="header" href="#motivation">Motivation</a></h2>
<p>As noted in <a href="https://github.com/rust-lang/rfcs/pull/39/files">RFC PR 39</a> (and reiterated in <a href="https://github.com/rust-lang/rfcs/pull/244">RFC PR 244</a>), modern general purpose allocators are good,
but due to the design tradeoffs they must make, cannot be optimal in
all contexts.  (It is worthwhile to also read discussion of this claim
in papers such as
<a href="#reconsidering-custom-memory-allocation">Reconsidering Custom Malloc</a>.)</p>
<p>Therefore, the standard library should allow clients to plug in their
own allocator for managing memory.</p>
<h3 id="allocators-are-used-in-c-system-programming"><a class="header" href="#allocators-are-used-in-c-system-programming">Allocators are used in C++ system programming</a></h3>
<p>The typical reasons given for use of custom allocators in C++ are among the
following:</p>
<ol>
<li>
<p>Speed: A custom allocator can be tailored to the particular
memory usage profiles of one client.  This can yield advantages
such as:</p>
<ul>
<li>
<p>A bump-pointer based allocator, when available, is faster
than calling <code>malloc</code>.</p>
</li>
<li>
<p>Adding memory padding can reduce/eliminate false sharing of
cache lines.</p>
</li>
</ul>
</li>
<li>
<p>Stability: By segregating different sub-allocators and imposing
hard memory limits upon them, one has a better chance of handling
out-of-memory conditions.</p>
<p>If everything comes from a single global heap, it becomes much
harder to handle out-of-memory conditions because by the time the
handler runs, it is almost certainly going to be unable to
allocate any memory for its own work.</p>
</li>
<li>
<p>Instrumentation and debugging: One can swap in a custom
allocator that collects data such as number of allocations,
or time for requests to be serviced.</p>
</li>
</ol>
<h3 id="allocators-should-feel-rustic"><a class="header" href="#allocators-should-feel-rustic">Allocators should feel “rustic”</a></h3>
<p>In addition, for Rust we want an allocator API design that leverages
the core type machinery and language idioms (e.g. using <code>Result</code> to
propagate dynamic error conditions), and provides
premade functions for common patterns for allocator clients (such as
allocating either single instances of a type, or arrays of some types
of dynamically-determined length).</p>
<h3 id="garbage-collection-integration"><a class="header" href="#garbage-collection-integration">Garbage Collection integration</a></h3>
<p>Finally, we want our allocator design to allow for a garbage
collection (GC) interface to be added in the future.</p>
<p>At the very least, we do not want to accidentally <em>disallow</em> GC by
choosing an allocator API that is fundamentally incompatible with it.</p>
<p>(However, this RFC does not actually propose a concrete solution for
how to integrate allocators with GC.)</p>
<h2 id="detailed-design"><a class="header" href="#detailed-design">Detailed design</a></h2>
<h3 id="the-allocator-trait-at-a-glance"><a class="header" href="#the-allocator-trait-at-a-glance">The <code>Allocator</code> trait at a glance</a></h3>
<p>The source code for the <code>Allocator</code> trait prototype is provided in an
<a href="#transcribed-source-for-allocator-trait-api">appendix</a>. But since that section is long, here
we summarize the high-level points of the <code>Allocator</code> API.</p>
<p>(See also the <a href="#a-walk-through-the-allocator-trait">walk thru</a> section, which actually links to
individual sections of code.)</p>
<ul>
<li>
<p>Basic implementation of the trait requires just two methods
(<code>alloc</code> and <code>dealloc</code>). You can get an initial implementation off
the ground with relatively little effort.</p>
</li>
<li>
<p>All methods that can fail to satisfy a request return a <code>Result</code>
(rather than building in an assumption that they panic or abort).</p>
<ul>
<li>
<p>Furthermore, allocator implementations are discouraged from
directly panicking or aborting on out-of-memory (OOM) during
calls to allocation methods; instead,
clients that do wish to report that OOM occurred via a particular
allocator can do so via the <code>Allocator::oom()</code> method.</p>
</li>
<li>
<p>OOM is not the only type of error that may occur in general;
allocators can inject more specific error types to indicate
why an allocation failed.</p>
</li>
</ul>
</li>
<li>
<p>The metadata for any allocation is captured in a <code>Layout</code>
abstraction. This type carries (at minimum) the size and alignment
requirements for a memory request.</p>
<ul>
<li>
<p>The <code>Layout</code> type provides a large family of functional construction
methods for building up the description of how memory is laid out.</p>
<ul>
<li>
<p>Any sized type <code>T</code> can be mapped to its <code>Layout</code>, via <code>Layout::new::&lt;T&gt;()</code>,</p>
</li>
<li>
<p>Heterogenous structure; e.g. <code>layout1.extend(layout2)</code>,</p>
</li>
<li>
<p>Homogeneous array types: <code>layout.repeat(n)</code> (for <code>n: usize</code>),</p>
</li>
<li>
<p>There are packed and unpacked variants for the latter two methods.</p>
</li>
</ul>
</li>
<li>
<p>Helper <code>Allocator</code> methods like <code>fn alloc_one</code> and <code>fn alloc_array</code> allow client code to interact with an allocator
without ever directly constructing a <code>Layout</code>.</p>
</li>
</ul>
</li>
<li>
<p>Once an <code>Allocator</code> implementor has the <code>fn alloc</code> and <code>fn dealloc</code>
methods working, it can provide overrides of the other methods,
providing hooks that take advantage of specific details of how your
allocator is working underneath the hood.</p>
<ul>
<li>
<p>In particular, the interface provides a few ways to let clients
potentially reuse excess memory associated with a block</p>
</li>
<li>
<p><code>fn realloc</code> is a common pattern (where the client hopes that
the method will reuse the original memory when satisfying the
<code>realloc</code> request).</p>
</li>
<li>
<p><code>fn alloc_excess</code> and <code>fn usable_size</code> provide an alternative
pattern, where your allocator tells the client about the excess
memory provided to satisfy a request, and the client can directly
expand into that excess memory, without doing round-trip requests
through the allocator itself.</p>
</li>
</ul>
</li>
</ul>
<h3 id="semantics-of-allocators-and-their-memory-blocks"><a class="header" href="#semantics-of-allocators-and-their-memory-blocks">Semantics of allocators and their memory blocks</a></h3>
<p>In general, an allocator provide access to a memory pool that owns
some amount of backing storage. The pool carves off chunks of that
storage and hands it out, via the allocator, as individual blocks of
memory to service client requests. (A “client” here is usually some
container library, like <code>Vec</code> or <code>HashMap</code>, that has been suitably
parameterized so that it has an <code>A:Allocator</code> type parameter.)</p>
<p>So, an interaction between a program, a collection library, and an
allocator might look like this:</p>
<img width="800" src="https://rawgit.com/pnkfelix/pnkfelix.github.com/69230e5f1ea140c0a09c5a9fdd7f0766207cdddd/Svg/allocator-msc.svg">
<p>If you cannot see the SVG linked here, try the <a href="#ascii-art-version-of-allocator-message-sequence-chart">ASCII art version</a> appendix.
Also, if you have suggestions for changes to the SVG, feel free to write them as a comment
in that appendix; (but be sure to be clear that you are pointing out a suggestion for the SVG).</p>
<p>In general, an allocator might be the backing memory pool itself; or
an allocator might merely be a <em>handle</em> that references the memory
pool. In the former case, when the allocator goes out of scope or is
otherwise dropped, the memory pool is dropped as well; in the latter
case, dropping the allocator has no effect on the memory pool.</p>
<ul>
<li>
<p>One allocator that acts as a handle is the global heap allocator,
whose associated pool is the low-level <code>#[allocator]</code> crate.</p>
</li>
<li>
<p>Another allocator that acts as a handle is a <code>&amp;'a Pool</code>, where
<code>Pool</code> is some structure implementing a sharable backing store.
The big <a href="#example-usage">example</a> section shows an instance of this.</p>
</li>
<li>
<p>An allocator that is its own memory pool would be a type
analogous to <code>Pool</code> that implements the <code>Allocator</code> interface
directly, rather than via <code>&amp;'a Pool</code>.</p>
</li>
<li>
<p>A case in the middle of the two extremes might be something like an
allocator of the form <code>Rc&lt;RefCell&lt;Pool&gt;&gt;</code>. This reflects <em>shared</em>
ownership between a collection of allocators handles: dropping one
handle will not drop the pool as long as at least one other handle
remains, but dropping the last handle will drop the pool itself.</p>
<p>FIXME: <code>RefCell&lt;Pool&gt;</code> is not going to work with the allocator API
envisaged here; see <a href="https://github.com/rust-lang/rfcs/pull/1398#issuecomment-162681096">comment from gankro</a>. We will need to
address this (perhaps just by pointing out that it is illegal and
suggesting a standard pattern to work around it) before this RFC
can be accepted.</p>
</li>
</ul>
<p>A client that is generic over all possible <code>A:Allocator</code> instances
cannot know which of the above cases it falls in. This has consequences
in terms of the restrictions that must be met by client code
interfacing with an allocator, which we discuss in a
later <a href="#allocators-and-lifetimes">section on lifetimes</a>.</p>
<h3 id="example-usage"><a class="header" href="#example-usage">Example Usage</a></h3>
<p>Lets jump into a demo. Here is a (super-dumb) bump-allocator that uses
the <code>Allocator</code> trait.</p>
<h4 id="implementing-the-allocator-trait"><a class="header" href="#implementing-the-allocator-trait">Implementing the <code>Allocator</code> trait</a></h4>
<p>First, the bump-allocator definition itself: each such allocator will
have its own name (for error reports from OOM), start and limit
pointers (<code>ptr</code> and <code>end</code>, respectively) to the backing storage it is
allocating into, as well as the byte alignment (<code>align</code>) of that
storage, and an <code>avail: AtomicPtr&lt;u8&gt;</code> for the cursor tracking how
much we have allocated from the backing storage.
(The <code>avail</code> field is an atomic because eventually we want to try
sharing this demo allocator across scoped threads.)</p>
<pre><code class="language-rust">#[derive(Debug)]
pub struct DumbBumpPool {
    name: &amp;'static str,
    ptr: *mut u8,
    end: *mut u8,
    avail: AtomicPtr&lt;u8&gt;,
    align: usize,
}</code></pre>
<p>The initial implementation is pretty straight forward: just immediately
allocate the whole pool’s backing storage.</p>
<p>(If we wanted to be really clever we might layer this type on top of
<em>another</em> allocator.
For this demo I want to try to minimize cleverness, so we will use
<code>heap::allocate</code> to grab the backing storage instead of taking an
<code>Allocator</code> of our own.)</p>
<pre><code class="language-rust">impl DumbBumpPool {
    pub fn new(name: &amp;'static str,
               size_in_bytes: usize,
               start_align: usize) -&gt; DumbBumpPool {
        unsafe {
            let ptr = heap::allocate(size_in_bytes, start_align);
            if ptr.is_null() { panic!("allocation failed."); }
            let end = ptr.offset(size_in_bytes as isize);
            DumbBumpPool {
                name: name,
                ptr: ptr, end: end, avail: AtomicPtr::new(ptr),
                align: start_align
            }
        }
    }
}</code></pre>
<p>Since clients are not allowed to have blocks that outlive their
associated allocator (see the <a href="#allocators-and-lifetimes">lifetimes</a> section),
it is sound for us to always drop the backing storage for an allocator
when the allocator itself is dropped
(regardless of what sequence of <code>alloc</code>/<code>dealloc</code> interactions occurred
with the allocator’s clients).</p>
<pre><code class="language-rust">impl Drop for DumbBumpPool {
    fn drop(&amp;mut self) {
        unsafe {
            let size = self.end as usize - self.ptr as usize;
            heap::deallocate(self.ptr, size, self.align);
        }
    }
}</code></pre>
<p>Here are some other design choices of note:</p>
<ul>
<li>
<p>Our Bump Allocator is going to use a most simple-minded deallocation
policy: calls to <code>fn dealloc</code> are no-ops. Instead, every request takes
up fresh space in the backing storage, until the pool is exhausted.
(This was one reason I use the word “Dumb” in its name.)</p>
</li>
<li>
<p>Since we want to be able to share the bump-allocator amongst multiple
(lifetime-scoped) threads, we will implement the <code>Allocator</code> interface
as a <em>handle</em> pointing to the pool; in this case, a simple reference.</p>
</li>
<li>
<p>Since the whole point of this particular bump-allocator is to
shared across threads (otherwise there would be no need to use
<code>AtomicPtr</code> for the <code>avail</code> field), we will want to implement the
(unsafe) <code>Sync</code> trait on it (doing this signals that it is safe to
send <code>&amp;DumbBumpPool</code> to other threads).</p>
</li>
</ul>
<p>Here is that <code>impl Sync</code>.</p>
<pre><code class="language-rust">/// Note of course that this impl implies we must review all other
/// code for DumbBumpPool even more carefully.
unsafe impl Sync for DumbBumpPool { }</code></pre>
<p>Here is the demo implementation of <code>Allocator</code> for the type.</p>
<pre><code class="language-rust">unsafe impl&lt;'a&gt; Allocator for &amp;'a DumbBumpPool {
    unsafe fn alloc(&amp;mut self, layout: alloc::Layout) -&gt; Result&lt;Address, AllocErr&gt; {
        let align = layout.align();
        let size = layout.size();

        let mut curr_addr = self.avail.load(Ordering::Relaxed);
        loop {
            let curr = curr_addr as usize;
            let (sum, oflo) = curr.overflowing_add(align - 1);
            let curr_aligned = sum &amp; !(align - 1);
            let remaining = (self.end as usize) - curr_aligned;
            if oflo || remaining &lt; size {
                return Err(AllocErr::Exhausted { request: layout.clone() });
            }

            let curr_aligned = curr_aligned as *mut u8;
            let new_curr = curr_aligned.offset(size as isize);

            let attempt = self.avail.compare_and_swap(curr_addr, new_curr, Ordering::Relaxed);
            // If the allocation attempt hits interference ...
            if curr_addr != attempt {
                curr_addr = attempt;
                continue; // .. then try again
            } else {
                println!("alloc finis ok: 0x{:x} size: {}", curr_aligned as usize, size);
                return Ok(curr_aligned);
            }
        }
    }

    unsafe fn dealloc(&amp;mut self, _ptr: Address, _layout: alloc::Layout) {
        // this bump-allocator just no-op's on dealloc
    }

    fn oom(&amp;mut self, err: AllocErr) -&gt; ! {
        let remaining = self.end as usize - self.avail.load(Ordering::Relaxed) as usize;
        panic!("exhausted memory in {} on request {:?} with avail: {}; self: {:?}",
               self.name, err, remaining, self);
    }

}</code></pre>
<p>(Niko Matsakis has pointed out that this particular allocator might
avoid interference errors by using fetch-and-add rather than
compare-and-swap. The devil’s in the details as to how one might
accomplish that while still properly adjusting for alignment; in any
case, the overall point still holds in cases outside of this specific
demo.)</p>
<p>And that is it; we are done with our allocator implementation.</p>
<h4 id="using-an-aallocator-from-the-client-side"><a class="header" href="#using-an-aallocator-from-the-client-side">Using an <code>A:Allocator</code> from the client side</a></h4>
<p>We assume that <code>Vec</code> has been extended with a <code>new_in</code> method that
takes an allocator argument that it uses to satisfy its allocation
requests.</p>
<pre><code class="language-rust">fn demo_alloc&lt;A1:Allocator, A2:Allocator, F:Fn()&gt;(a1:A1, a2: A2, print_state: F) {
    let mut v1 = Vec::new_in(a1);
    let mut v2 = Vec::new_in(a2);
    println!("demo_alloc, v1; {:?} v2: {:?}", v1, v2);
    for i in 0..10 {
        v1.push(i as u64 * 1000);
        v2.push(i as u8);
        v2.push(i as u8);
    }
    println!("demo_alloc, v1; {:?} v2: {:?}", v1, v2);
    print_state();
    for i in 10..100 {
        v1.push(i as u64 * 1000);
        v2.push(i as u8);
        v2.push(i as u8);
    }
    println!("demo_alloc, v1.len: {} v2.len: {}", v1.len(), v2.len());
    print_state();
    for i in 100..1000 {
        v1.push(i as u64 * 1000);
        v2.push(i as u8);
        v2.push(i as u8);
    }
    println!("demo_alloc, v1.len: {} v2.len: {}", v1.len(), v2.len());
    print_state();
}

fn main() {
    use std::thread::catch_panic;

    if let Err(panicked) = catch_panic(|| {
        let alloc = DumbBumpPool::new("demo-bump", 4096, 1);
        demo_alloc(&amp;alloc, &amp;alloc, || println!("alloc: {:?}", alloc));
    }) {
        match panicked.downcast_ref::&lt;String&gt;() {
            Some(msg) =&gt; {
                println!("DumbBumpPool panicked: {}", msg);
            }
            None =&gt; {
                println!("DumbBumpPool panicked");
            }
        }
    }

    // // The below will be (rightly) rejected by compiler when
    // // all pieces are properly in place: It is not valid to
    // // have the vector outlive the borrowed allocator it is
    // // referencing.
    //
    // let v = {
    //     let alloc = DumbBumpPool::new("demo2", 4096, 1);
    //     let mut v = Vec::new_in(&amp;alloc);
    //     for i in 1..4 { v.push(i); }
    //     v
    // };

    let alloc = DumbBumpPool::new("demo-bump", 4096, 1);
    for i in 0..100 {
        let r = ::std::thread::scoped(|| {
            let v = Vec::new_in(&amp;alloc);
            for j in 0..10 {
                v.push(j);
            }
        });
    }

    println!("got here");
}</code></pre>
<p>And that’s all to the demo, folks.</p>
<h4 id="what-about-standard-library-containers"><a class="header" href="#what-about-standard-library-containers">What about standard library containers?</a></h4>
<p>The intention of this RFC is that the Rust standard library will be
extended with parameteric allocator support: <code>Vec</code>, <code>HashMap</code>, etc
should all eventually be extended with the ability to use an
alternative allocator for their backing storage.</p>
<p>However, this RFC does not prescribe when or how this should happen.</p>
<p>Under the design of this RFC, Allocators parameters are specified via
a <em>generic type parameter</em> on the container type. This strongly
implies that <code>Vec&lt;T&gt;</code> and <code>HashMap&lt;K, V&gt;</code> will need to be extended
with an allocator type parameter, i.e.: <code>Vec&lt;T, A:Allocator&gt;</code> and
<code>HashMap&lt;K, V, A:Allocator&gt;</code>.</p>
<p>There are two reasons why such extension is left to later work, after
this RFC.</p>
<h5 id="default-type-parameter-fallback"><a class="header" href="#default-type-parameter-fallback">Default type parameter fallback</a></h5>
<p>On its own, such a change would be backwards incompatible (i.e. a huge
breaking change), and also would simply be just plain inconvenient for
typical use cases. Therefore, the newly added type parameters will
almost certainly require a <em>default type</em>: <code>Vec&lt;T: A:Allocator=HeapAllocator&gt;</code> and
<code>HashMap&lt;K,V,A:Allocator=HeapAllocator&gt;</code>.</p>
<p>Default type parameters themselves, in the context of type definitions,
are a stable part of the Rust language.</p>
<p>However, the exact semantics of how default type parameters interact
with inference is still being worked out (in part <em>because</em> allocators
are a motivating use case), as one can see by reading the following:</p>
<ul>
<li>
<p>RFC 213, “Finalize defaulted type parameters”: https://github.com/rust-lang/rfcs/blob/master/text/0213-defaulted-type-params.md</p>
</li>
<li>
<p>Tracking Issue for RFC 213: Default Type Parameter Fallback: https://github.com/rust-lang/rust/issues/27336</p>
</li>
<li>
<p>Feature gate defaulted type parameters appearing outside of types: https://github.com/rust-lang/rust/pull/30724</p>
</li>
</ul>
<h5 id="fully-general-container-integration-needs-dropck-eyepatch"><a class="header" href="#fully-general-container-integration-needs-dropck-eyepatch">Fully general container integration needs Dropck Eyepatch</a></h5>
<p>The previous problem was largely one of programmer
ergonomics. However, there is also a subtle soundness issue that
arises due to an current implementation artifact.</p>
<p>Standard library types like <code>Vec&lt;T&gt;</code> and <code>HashMap&lt;K,V&gt;</code> allow
instantiating the generic parameters <code>T</code>, <code>K</code>, <code>V</code> with types holding
lifetimes that do not strictly outlive that of the container itself.
(I will refer to such instantiations of <code>Vec</code> and <code>HashMap</code>
“same-lifetime instances” as a shorthand in this discussion.)</p>
<p>Same-lifetime instance support is currently implemented for <code>Vec</code> and
<code>HashMap</code> via an unstable attribute that is too
coarse-grained. Therefore, we cannot soundly add the allocator
parameter to <code>Vec</code> and <code>HashMap</code> while also continuing to allow
same-lifetime instances without first addressing this overly coarse
attribute. I have an open RFC to address this, the “Dropck Eyepatch”
RFC; that RFC explains in more detail why this problem arises, using
allocators as a specific motivating use case.</p>
<ul>
<li>
<p>Concrete code illustrating this exact example (part of Dropck Eyepatch RFC):
https://github.com/pnkfelix/rfcs/blob/dropck-eyepatch/text/0000-dropck-param-eyepatch.md#example-vect-aallocatordefaultallocator</p>
</li>
<li>
<p>Nonparametric dropck RFC https://github.com/rust-lang/rfcs/blob/master/text/1238-nonparametric-dropck.md</p>
</li>
</ul>
<h5 id="standard-library-containers-conclusion"><a class="header" href="#standard-library-containers-conclusion">Standard library containers conclusion</a></h5>
<p>Rather than wait for the above issues to be resolved, this RFC
proposes that we at least stabilize the <code>Allocator</code> trait interface;
then we will at least have a starting point upon which to prototype
standard library integration.</p>
<h3 id="allocators-and-lifetimes"><a class="header" href="#allocators-and-lifetimes">Allocators and lifetimes</a></h3>
<p>As mentioned above, allocators provide access to a memory pool. An
allocator can <em>be</em> the pool (in the sense that the allocator owns the
backing storage that represents the memory blocks it hands out), or an
allocator can just be a handle that points at the pool.</p>
<p>Some pools have indefinite extent. An example of this is the global
heap allocator, requesting memory directly from the low-level
<code>#[allocator]</code> crate. Clients of an allocator with such a pool need
not think about how long the allocator lives; instead, they can just
freely allocate blocks, use them at will, and deallocate them at
arbitrary points in the future. Memory blocks that come from such a
pool will leak if it is not explicitly deallocated.</p>
<p>Other pools have limited extent: they are created, they build up
infrastructure to manage their blocks of memory, and at some point,
such pools are torn down. Memory blocks from such a pool may or may
not be returned to the operating system during that tearing down.</p>
<p>There is an immediate question for clients of an allocator with the
latter kind of pool (i.e. one of limited extent): whether it should
attempt to spend time deallocating such blocks, and if so, at what
time to do so?</p>
<p>Again, note:</p>
<ul>
<li>
<p>generic clients (i.e. that accept any <code>A:Allocator</code>) <em>cannot know</em>
what kind of pool they have, or how it relates to the allocator it
is given,</p>
</li>
<li>
<p>dropping the client’s allocator may or may not imply the dropping
of the pool itself!</p>
</li>
</ul>
<p>That is, code written to a specific <code>Allocator</code> implementation may be
able to make assumptions about the relationship between the memory
blocks and the allocator(s), but the generic code we expect the
standard library to provide cannot make such assumptions.</p>
<p>To satisfy the above scenarios in a sane, consistent, general fashion,
the <code>Allocator</code> trait assumes/requires all of the following conditions.
(Note: this list of conditions uses the phrases “should”, “must”, and “must not”
in a formal manner, in the style of <a href="https://www.ietf.org/rfc/rfc2119.txta">IETF RFC 2119</a>.)</p>
<ol>
<li>
<p>(for allocator impls and clients): in the absence of other
information (e.g. specific allocator implementations), all blocks
from a given pool have lifetime equivalent to the lifetime of the
pool.</p>
<p>This implies if a client is going to read from, write to, or
otherwise manipulate a memory block, the client <em>must</em> do so before
its associated pool is torn down.</p>
<p>(It also implies the converse: if a client can prove that the pool
for an allocator is still alive, then it can continue to work
with a memory block from that allocator even after the allocator
is dropped.)</p>
</li>
<li>
<p>(for allocator impls): an allocator <em>must not</em> outlive its
associated pool.</p>
<p>All clients can assume this in their code.</p>
<p>(This constraint provides generic clients the preconditions they
need to satisfy the first condition. In particular, even though
clients do not generally know what kind of pool is associated with
its allocator, it can conservatively assume that all blocks will
live at least as long as the allocator itself.)</p>
</li>
<li>
<p>(for allocator impls and clients): all clients of an allocator
<em>should</em> eventually call the <code>dealloc</code> method on every block they
want freed (otherwise, memory may leak).</p>
<p>However, allocator implementations <em>must</em> remain sound even if
this condition is not met: If <code>dealloc</code> is not invoked for all
blocks and this condition is somehow detected, then an allocator
can panic (or otherwise signal failure), but that sole violation
must not cause undefined behavior.</p>
<p>(This constraint is to encourage generic client authors to write
code that will not leak memory when instantiated with allocators
of indefinite extent, such as the global heap allocator.)</p>
</li>
<li>
<p>(for allocator impls): moving an allocator value <em>must not</em>
invalidate its outstanding memory blocks.</p>
<p>All clients can assume this in their code.</p>
<p>So if a client allocates a block from an allocator (call it <code>a1</code>)
and then <code>a1</code> moves to a new place (e.g. via<code>let a2 = a1;</code>), then
it remains sound for the client to deallocate that block via
<code>a2</code>.</p>
<p>Note that this implies that it is not sound to implement an
allocator that embeds its own pool structurally inline.</p>
<p>E.g. this is <em>not</em> a legal allocator:</p>
<pre><code class="language-rust">struct MegaEmbedded { pool: [u8; 1024*1024], cursor: usize, ... }
impl Allocator for MegaEmbedded { ... } // INVALID IMPL</code></pre>
<p>The latter impl is simply unreasonable (at least if one is
intending to satisfy requests by returning pointers into
<code>self.bytes</code>).</p>
<p>Note that an allocator that owns its pool <em>indirectly</em>
(i.e. does not have the pool’s state embedded in the allocator) is fine:</p>
<pre><code class="language-rust">struct MegaIndirect { pool: *mut [u8; 1024*1024], cursor: usize, ... }
impl Allocator for MegaIndirect { ... } // OKAY</code></pre>
<p>(I originally claimed that <code>impl Allocator for &amp;mut MegaEmbedded</code>
would also be a legal example of an allocator that is an indirect handle
to an unembedded pool, but others pointed out that handing out the
addresses pointing into that embedded pool could end up violating our
aliasing rules for <code>&amp;mut</code>. I obviously did not expect that outcome; I
would be curious to see what the actual design space is here.)</p>
</li>
<li>
<p>(for allocator impls and clients) if an allocator is cloneable, the
client <em>can assume</em> that all clones
are interchangeably compatible in terms of their memory blocks: if
allocator <code>a2</code> is a clone of <code>a1</code>, then one can allocate a block
from <code>a1</code> and return it to <code>a2</code>, or vice versa, or use <code>a2.realloc</code>
on the block, et cetera.</p>
<p>This essentially means that any cloneable
allocator <em>must</em> be a handle indirectly referencing a pool of some
sort. (Though do remember that such handles can collectively share
ownership of their pool, such as illustrated in the
<code>Rc&lt;RefCell&lt;Pool&gt;&gt;</code> example given earlier.)</p>
<p>(Note: one might be tempted to further conclude that this also
implies that allocators implementing <code>Copy</code> must have pools of
indefinite extent. While this seems reasonable for Rust as it
stands today, I am slightly worried whether it would continue to
hold e.g.  in a future version of Rust with something like
<code>Gc&lt;GcPool&gt;: Copy</code>, where the <code>GcPool</code> and its blocks is reclaimed
(via finalization) sometime after being determined to be globally
unreachable. Then again, perhaps it would be better to simply say
“we will not support that use case for the allocator API”, so that
clients would be able to employ the reasoning outlined in the
outset of this paragraph.)</p>
</li>
</ol>
<h3 id="a-walk-through-the-allocator-trait"><a class="header" href="#a-walk-through-the-allocator-trait">A walk through the Allocator trait</a></h3>
<h4 id="role-based-type-aliases"><a class="header" href="#role-based-type-aliases">Role-Based Type Aliases</a></h4>
<p>Allocation code often needs to deal with values that boil down to a
<code>usize</code> in the end. But there are distinct roles (e.g. “size”,
“alignment”) that such values play, and I decided those roles would be
worth hard-coding into the method signatures.</p>
<ul>
<li>Therefore, I made <a href="#type-aliases">type aliases</a> for <code>Size</code>, <code>Capacity</code>, <code>Alignment</code>, and <code>Address</code>.</li>
</ul>
<h4 id="basic-implementation"><a class="header" href="#basic-implementation">Basic implementation</a></h4>
<p>An instance of an allocator has many methods, but an implementor of
the trait need only provide two method bodies: <a href="#allocator-core-alloc-and-dealloc">alloc and dealloc</a>.</p>
<p>(This is only <em>somewhat</em> analogous to the <code>Iterator</code> trait in Rust. It
is currently very uncommon to override any methods of <code>Iterator</code> except
for <code>fn next</code>. However, I expect it will be much more common for
<code>Allocator</code> to override at least some of the other methods, like <code>fn realloc</code>.)</p>
<p>The <code>alloc</code> method returns an <code>Address</code> when it succeeds, and
<code>dealloc</code> takes such an address as its input. But the client must also
provide metadata for the allocated block like its size and alignment.
This is encapsulated in the <code>Layout</code> argument to <code>alloc</code> and <code>dealloc</code>.</p>
<h4 id="memory-layouts"><a class="header" href="#memory-layouts">Memory layouts</a></h4>
<p>A <code>Layout</code> just carries the metadata necessary for satisfying an
allocation request. Its (current, private) representation is just a
size and alignment.</p>
<p>The more interesting thing about <code>Layout</code> is the
family of public methods associated with it for building new layouts via
composition; these are shown in the <a href="#layout-api">layout api</a>.</p>
<h4 id="reallocation-methods"><a class="header" href="#reallocation-methods">Reallocation Methods</a></h4>
<p>Of course, real-world allocation often needs more than just
<code>alloc</code>/<code>dealloc</code>: in particular, one often wants to avoid extra
copying if the existing block of memory can be conceptually expanded
in place to meet new allocation needs. In other words, we want
<code>realloc</code>, plus alternatives to it (<code>alloc_excess</code>) that allow clients to avoid
round-tripping through the allocator API.</p>
<p>For this, the <a href="#allocator-methods-for-memory-reuse">memory reuse</a> family of methods is appropriate.</p>
<h4 id="type-based-helper-methods"><a class="header" href="#type-based-helper-methods">Type-based Helper Methods</a></h4>
<p>Some readers might skim over the <code>Layout</code> API and immediately say “yuck,
all I wanted to do was allocate some nodes for a tree-structure and
let my clients choose how the backing memory is chosen! Why do I have
to wrestle with this <code>Layout</code> business?”</p>
<p>I agree with the sentiment; that’s why the <code>Allocator</code> trait provides
a family of methods capturing <a href="#allocator-convenience-methods-for-common-usage-patterns">common usage patterns</a>,
for example, <code>a.alloc_one::&lt;T&gt;()</code> will return a <code>Unique&lt;T&gt;</code> (or error).</p>
<h3 id="unchecked-variants"><a class="header" href="#unchecked-variants">Unchecked variants</a></h3>
<p>Almost all of the methods above return <code>Result</code>, and guarantee some
amount of input validation. (This is largely because I observed code
duplication doing such validation on the client side; or worse, such
validation accidentally missing.)</p>
<p>However, some clients will want to bypass such checks (and do it
without risking undefined behavior, namely by ensuring the method preconditions
hold via local invariants in their container type).</p>
<p>For these clients, the <code>Allocator</code> trait provides
<a href="#allocator-unchecked-method-variants">“unchecked” variants</a> of nearly all of its
methods; so <code>a.alloc_unchecked(layout)</code> will return an <code>Option&lt;Address&gt;</code>
(where <code>None</code> corresponds to allocation failure).</p>
<p>The idea here is that <code>Allocator</code> implementors are encouraged
to streamline the implementations of such methods by assuming that all
of the preconditions hold.</p>
<ul>
<li>
<p>However, to ease initial <code>impl Allocator</code> development for a given
type, all of the unchecked methods have default implementations
that call out to their checked counterparts.</p>
</li>
<li>
<p>(In other words, “unchecked” is in some sense a privilege being
offered to impl’s; but there is no guarantee that an arbitrary impl
takes advantage of the privilege.)</p>
</li>
</ul>
<h3 id="object-oriented-allocators"><a class="header" href="#object-oriented-allocators">Object-oriented Allocators</a></h3>
<p>Finally, we get to object-oriented programming.</p>
<p>In general, we expect allocator-parametric code to opt <em>not</em> to use
trait objects to generalize over allocators, but instead to use
generic types and instantiate those types with specific concrete
allocators.</p>
<p>Nonetheless, it <em>is</em> an option to write <code>Box&lt;Allocator&gt;</code> or <code>&amp;Allocator</code>.</p>
<ul>
<li>(The allocator methods that are not object-safe, like
<code>fn alloc_one&lt;T&gt;(&amp;mut self)</code>, have a clause <code>where Self: Sized</code> to
ensure that their presence does not cause the <code>Allocator</code> trait as
a whole to become non-object-safe.)</li>
</ul>
<h3 id="why-this-api"><a class="header" href="#why-this-api">Why this API</a></h3>
<p>Here are some quick points about how this API was selected</p>
<h4 id="why-not-just-freeptr-for-deallocation"><a class="header" href="#why-not-just-freeptr-for-deallocation">Why not just <code>free(ptr)</code> for deallocation?</a></h4>
<p>As noted in <a href="https://github.com/rust-lang/rfcs/pull/39/files">RFC PR 39</a> (and reiterated in <a href="https://github.com/rust-lang/rfcs/pull/244">RFC PR 244</a>), the basic <code>malloc</code> interface
{<code>malloc(size) -&gt; ptr</code>, <code>free(ptr)</code>, <code>realloc(ptr, size) -&gt; ptr</code>} is
lacking in a number of ways: <code>malloc</code> lacks the ability to request a
particular alignment, and <code>realloc</code> lacks the ability to express a
copy-free “reuse the input, or do nothing at all” request.  Another
problem with the <code>malloc</code> interface is that it burdens the allocator
with tracking the sizes of allocated data and re-extracting the
allocated size from the <code>ptr</code> in <code>free</code> and <code>realloc</code> calls (the
latter can be very cheap, but there is still no reason to pay that
cost in a language like Rust where the relevant size is often already
immediately available as a compile-time constant).</p>
<p>Therefore, in the name of (potential best-case) speed, we want to
require client code to provide the metadata like size and alignment
to both the allocation and deallocation call sites.</p>
<h4 id="why-not-just-allocdealloc-or-allocdeallocrealloc"><a class="header" href="#why-not-just-allocdealloc-or-allocdeallocrealloc">Why not just <code>alloc</code>/<code>dealloc</code> (or <code>alloc</code>/<code>dealloc</code>/<code>realloc</code>)?</a></h4>
<ul>
<li>
<p>The <code>alloc_one</code>/<code>dealloc_one</code> and <code>alloc_array</code>/<code>dealloc_array</code>
capture a very common pattern for allocation of memory blocks where
a simple value or array type is being allocated.</p>
</li>
<li>
<p>The <code>alloc_array_unchecked</code> and <code>dealloc_array_unchecked</code> likewise
capture a common pattern, but are “less safe” in that they put more
of an onus on the caller to validate the input parameters before
calling the methods.</p>
</li>
<li>
<p>The <code>alloc_excess</code> and <code>realloc_excess</code> methods provide a way for
callers who can make use of excess memory to avoid unnecessary calls
to <code>realloc</code>.</p>
</li>
</ul>
<h4 id="why-the-layout-abstraction"><a class="header" href="#why-the-layout-abstraction">Why the <code>Layout</code> abstraction?</a></h4>
<p>While we do want to require clients to hand the allocator the size and
alignment, we have found that the code to compute such things follows
regular patterns. It makes more sense to factor those patterns out
into a common abstraction; this is what <code>Layout</code> provides: a high-level
API for describing the memory layout of a composite structure by
composing the layout of its subparts.</p>
<h4 id="why-return-result-rather-than-a-raw-pointer"><a class="header" href="#why-return-result-rather-than-a-raw-pointer">Why return <code>Result</code> rather than a raw pointer?</a></h4>
<p>My hypothesis is that the standard allocator API should embrace
<code>Result</code> as the standard way for describing local error conditions in
Rust.</p>
<ul>
<li>A previous version of this RFC attempted to ensure that the use of
the <code>Result</code> type could avoid any additional overhead over a raw
pointer return value, by using a <code>NonZero</code> address type and a
zero-sized error type attached to the trait via an associated
<code>Error</code> type. But during the RFC process we decided that this
was not necessary.</li>
</ul>
<h4 id="why-return-result-rather-than-directly-oom-on-failure"><a class="header" href="#why-return-result-rather-than-directly-oom-on-failure">Why return <code>Result</code> rather than directly <code>oom</code> on failure</a></h4>
<p>Again, my hypothesis is that the standard allocator API should embrace
<code>Result</code> as the standard way for describing local error conditions in
Rust.</p>
<p>I want to leave it up to the clients to decide if they can respond to
out-of-memory (OOM) conditions on allocation failure.</p>
<p>However, since I also suspect that some programs would benefit from
contextual information about <em>which</em> allocator is reporting memory
exhaustion, I have made <code>oom</code> a method of the <code>Allocator</code> trait, so
that allocator clients have the option of calling that on error.</p>
<h4 id="why-is-usable_size-ever-needed-why-not-call-layoutsize-directly-as-is-done-in-the-default-implementation"><a class="header" href="#why-is-usable_size-ever-needed-why-not-call-layoutsize-directly-as-is-done-in-the-default-implementation">Why is <code>usable_size</code> ever needed? Why not call <code>layout.size()</code> directly, as is done in the default implementation?</a></h4>
<p><code>layout.size()</code> returns the minimum required size that the client needs.
In a block-based allocator, this may be less than the <em>actual</em> size
that the allocator would ever provide to satisfy that kind of
request. Therefore, <code>usable_size</code> provides a way for clients to
observe what the minimum actual size of an allocated block for
that<code>layout</code> would be, for a given allocator.</p>
<p>(Note that the documentation does say that in general it is better for
clients to use <code>alloc_excess</code> and <code>realloc_excess</code> instead, if they
can, as a way to directly observe the <em>actual</em> amount of slop provided
by the particular allocator.)</p>
<h4 id="why-is-allocator-an-unsafe-trait"><a class="header" href="#why-is-allocator-an-unsafe-trait">Why is <code>Allocator</code> an <code>unsafe trait</code>?</a></h4>
<p>It just seems like a good idea given how much of the standard library
is going to assume that allocators are implemented according to their
specification.</p>
<p>(I had thought that <code>unsafe fn</code> for the methods would suffice, but
that is putting the burden of proof (of soundness) in the <em>wrong</em>
direction…)</p>
<h3 id="the-gc-integration-strategy"><a class="header" href="#the-gc-integration-strategy">The GC integration strategy</a></h3>
<p>One of the main reasons that <a href="https://github.com/rust-lang/rfcs/pull/39/files">RFC PR 39</a> was not merged as written
was because it did not account for garbage collection (GC).</p>
<p>In particular, assuming that we eventually add support for GC in some
form, then any value that holds a reference to an object on the GC’ed
heap will need some linkage to the GC. In particular, if the <em>only</em>
such reference (i.e. the one with sole ownership) is held in a block
managed by a user-defined allocator, then we need to ensure that all
such references are found when the GC does its work.</p>
<p>The Rust project has control over the <code>libstd</code> provided allocators, so
the team can adapt them as necessary to fit the needs of whatever GC
designs come around. But the same is not true for user-defined
allocators: we want to ensure that adding support for them does not
inadvertently kill any chance for adding GC later.</p>
<h4 id="the-inspiration-for-layout"><a class="header" href="#the-inspiration-for-layout">The inspiration for Layout</a></h4>
<p>Some aspects of the design of this RFC were selected in the hopes that
it would make such integration easier. In particular, the introduction
of the relatively high-level <code>Kind</code> abstraction was developed, in
part, as a way that a GC-aware allocator would build up a tracing
method associated with a layout.</p>
<p>Then I realized that the <code>Kind</code> abstraction may be valuable on its
own, without GC: It encapsulates important patterns when working with
representing data as memory records.</p>
<p>(Later we decided to rename <code>Kind</code> to <code>Layout</code>, in part to avoid
confusion with the use of the word “kind” in the context of
higher-kinded types (HKT).)</p>
<p>So, this RFC offers the <code>Layout</code> abstraction without promising that it
solves the GC problem. (It might, or it might not; we don’t know yet.)</p>
<h4 id="forwards-compatibility"><a class="header" href="#forwards-compatibility">Forwards-compatibility</a></h4>
<p>So what <em>is</em> the solution for forwards-compatibility?</p>
<p>It is this: Rather than trying to build GC support into the
<code>Allocator</code> trait itself, we instead assume that when GC support
comes, it may come with a new trait (call it <code>GcAwareAllocator</code>).</p>
<ul>
<li>(Perhaps we will instead use an attribute; the point is, whatever
option we choose can be incorporated into the meta-data for a
crate.)</li>
</ul>
<p>Allocators that are GC-compatible have to explicitly declare
themselves as such, by implementing <code>GcAwareAllocator</code>, which will
then impose new conditions on the methods of <code>Allocator</code>, for example
ensuring e.g. that allocated blocks of memory can be scanned
(i.e. “parsed”) by the GC (if that in fact ends up being necessary).</p>
<p>This way, we can deploy an <code>Allocator</code> trait API today that does not
provide the necessary reflective hooks that a GC would need to access.</p>
<p>Crates that define their own <code>Allocator</code> implementations without also
claiming them to be GC-compatible will be forbidden from linking with
crates that require GC support. (In other words, when GC support
comes, we assume that the linking component of the Rust compiler will
be extended to check such compatibility requirements.)</p>
<h2 id="drawbacks"><a class="header" href="#drawbacks">Drawbacks</a></h2>
<p>The API may be over-engineered.</p>
<p>The core set of methods (the ones without <code>unchecked</code>) return
<code>Result</code> and potentially impose unwanted input validation overhead.</p>
<ul>
<li>The <code>_unchecked</code> variants are intended as the response to that,
for clients who take care to validate the many preconditions
themselves in order to minimize the allocation code paths.</li>
</ul>
<h2 id="alternatives"><a class="header" href="#alternatives">Alternatives</a></h2>
<h3 id="just-adopt-rfc-pr-39-with-this-rfcs-gc-strategy"><a class="header" href="#just-adopt-rfc-pr-39-with-this-rfcs-gc-strategy">Just adopt <a href="https://github.com/rust-lang/rfcs/pull/39/files">RFC PR 39</a> with this RFC’s GC strategy</a></h3>
<p>The GC-compatibility strategy described here (in <a href="#the-gc-integration-strategy">gc integration</a>)
might work with a large number of alternative designs, such as that
from <a href="https://github.com/rust-lang/rfcs/pull/39/files">RFC PR 39</a>.</p>
<p>While that is true, it seems like it would be a little short-sighted.
In particular, I have neither proven <em>nor</em> disproven the value of
<code>Layout</code> system described here with respect to GC integration.</p>
<p>As far as I know, it is the closest thing we have to a workable system
for allowing client code of allocators to accurately describe the
layout of values they are planning to allocate, which is the main
ingredient I believe to be necessary for the kind of dynamic
reflection that a GC will require of a user-defined allocator.</p>
<h3 id="make-layout-an-associated-type-of-allocator-trait"><a class="header" href="#make-layout-an-associated-type-of-allocator-trait">Make <code>Layout</code> an associated type of <code>Allocator</code> trait</a></h3>
<p>I explored making an <code>AllocLayout</code> bound and then having</p>
<pre><code class="language-rust">pub unsafe trait Allocator {
    /// Describes the sort of records that this allocator can
    /// construct.
    type Layout: AllocLayout;

    ...
}</code></pre>
<p>Such a design might indeed be workable. (I found it awkward, which is
why I abandoned it.)</p>
<p>But the question is: What benefit does it bring?</p>
<p>The main one I could imagine is that it might allow us to introduce a
division, at the type-system level, between two kinds of allocators:
those that are integrated with the GC (i.e., have an associated
<code>Allocator::Layout</code> that ensures that all allocated blocks are scannable
by a GC) and allocators that are <em>not</em> integrated with the GC (i.e.,
have an associated <code>Allocator::Layout</code> that makes no guarantees about
one will know how to scan the allocated blocks.</p>
<p>However, no such design has proven itself to be “obviously feasible to
implement,” and therefore it would be unreasonable to make the <code>Layout</code>
an associated type of the <code>Allocator</code> trait without having at least a
few motivating examples that <em>are</em> clearly feasible and useful.</p>
<h3 id="variations-on-the-layout-api"><a class="header" href="#variations-on-the-layout-api">Variations on the <code>Layout</code> API</a></h3>
<ul>
<li>
<p>Should <code>Layout</code> offer a <code>fn resize(&amp;self, new_size: usize) -&gt; Layout</code> constructor method?
(Such a method would rule out deriving GC tracers from layouts; but we could
maybe provide it as an <code>unsafe</code> method.)</p>
</li>
<li>
<p>Should <code>Layout</code> ensure an invariant that its associated size is
always a multiple of its alignment?</p>
<ul>
<li>
<p>Doing this would allow simplifying a small part of the API,
namely the distinct <code>Layout::repeat</code> (returns both a layout and an
offset) versus <code>Layout::array</code> (where the offset is derivable from
the input <code>T</code>).</p>
</li>
<li>
<p>Such a constraint would have precedent; in particular, the
<code>aligned_alloc</code> function of C11 requires the given size
be a multiple of the alignment.</p>
</li>
<li>
<p>On the other hand, both the system and jemalloc allocators seem
to support more flexible allocation patterns. Imposing the above
invariant implies a certain loss of expressiveness over what we
already provide today.</p>
</li>
</ul>
</li>
<li>
<p>Should <code>Layout</code> ensure an invariant that its associated size is always positive?</p>
<ul>
<li>
<p>Pro: Removes something that allocators would need to check about
input layouts (the backing memory allocators will tend to require
that the input sizes are positive).</p>
</li>
<li>
<p>Con: Requiring positive size means that zero-sized types do not have an associated
<code>Layout</code>. That’s not the end of the world, but it does make the <code>Layout</code> API slightly
less convenient (e.g. one cannot use <code>extend</code> with a zero-sized layout to
forcibly inject padding, because zero-sized layouts do not exist).</p>
</li>
</ul>
</li>
<li>
<p>Should <code>Layout::align_to</code> add padding to the associated size? (Probably not; this would
make it impossible to express certain kinds of patteerns.)</p>
</li>
<li>
<p>Should the <code>Layout</code> methods that might “fail” return <code>Result</code> instead of <code>Option</code>?</p>
</li>
</ul>
<h3 id="variations-on-the-allocator-api"><a class="header" href="#variations-on-the-allocator-api">Variations on the <code>Allocator</code> API</a></h3>
<ul>
<li>
<p>Should the allocator methods take <code>&amp;self</code> or <code>self</code> rather than <code>&amp;mut self</code>.</p>
<p>As noted during in the RFC comments, nearly every trait goes through a bit
of an identity crisis in terms of deciding what kind of <code>self</code> parameter is
appropriate.</p>
<p>The justification for <code>&amp;mut self</code> is this:</p>
<ul>
<li>
<p>It does not restrict allocator implementors from making sharable allocators:
to do so, just do <code>impl&lt;'a&gt; Allocator for &amp;'a MySharedAlloc</code>, as illustrated
in the <code>DumbBumpPool</code> example.</p>
</li>
<li>
<p><code>&amp;mut self</code> is better than <code>&amp;self</code> for simple allocators that are <em>not</em> sharable.
<code>&amp;mut self</code> ensures that the allocation methods have exclusive
access to the underlying allocator state, without resorting to a
lock. (Another way of looking at it: It moves the onus of using a
lock outward, to the allocator clients.)</p>
</li>
<li>
<p>One might think that the points made
above apply equally well to <code>self</code> (i.e., if you want to implement an allocator
that wants to take itself via a <code>&amp;mut</code>-reference when the methods take <code>self</code>,
then do <code>impl&lt;'a&gt; Allocator for &amp;'a mut MyUniqueAlloc</code>).</p>
<p>However, the problem with <code>self</code> is that if you want to use an
allocator for <em>more than one</em> allocation, you will need to call
<code>clone()</code> (or make the allocator parameter implement
<code>Copy</code>). This means in practice all allocators will need to
support <code>Clone</code> (and thus support sharing in general, as
discussed in the <a href="#allocators-and-lifetimes">Allocators and lifetimes</a> section).</p>
<p>(Remember, I’m thinking about allocator-parametric code like
<code>Vec&lt;T, A:Allocator&gt;</code>, which does not know if the <code>A</code> is a
<code>&amp;mut</code>-reference. In that context, therefore one cannot assume
that reborrowing machinery is available to the client code.)</p>
<p>Put more simply, requiring that allocators implement <code>Clone</code> means
that it will <em>not</em> be practical to do
<code>impl&lt;'a&gt; Allocator for &amp;'a mut MyUniqueAlloc</code>.</p>
<p>By using <code>&amp;mut self</code> for the allocation methods, we can encode
the expected use case of an <em>unshared</em> allocator that is used
repeatedly in a linear fashion (e.g. vector that needs to
reallocate its backing storage).</p>
</li>
</ul>
</li>
<li>
<p>Should the types representing allocated storage have lifetimes attached?
(E.g. <code>fn alloc&lt;'a&gt;(&amp;mut self, layout: &amp;alloc::Layout) -&gt; Address&lt;'a&gt;</code>.)</p>
<p>I think Gankro <a href="https://github.com/rust-lang/rfcs/pull/1398#issuecomment-164003160">put it best</a>:</p>
<blockquote>
<p>This is a low-level unsafe interface, and the expected usecases make it
both quite easy to avoid misuse, and impossible to use lifetimes
(you want a struct to store the allocator and the allocated elements).
Any time we’ve tried to shove more lifetimes into these kinds of
interfaces have just been an annoying nuisance necessitating
copy-lifetime/transmute nonsense.</p>
</blockquote>
</li>
<li>
<p>Should <code>Allocator::alloc</code> be safe instead of <code>unsafe fn</code>?</p>
<ul>
<li>
<p>Clearly <code>fn dealloc</code> and <code>fn realloc</code> need to be <code>unsafe</code>, since
feeding in improper inputs could cause unsound behavior. But is
there any analogous input to <code>fn alloc</code> that could cause
unsoundness (assuming that the <code>Layout</code> struct enforces invariants
like “the associated size is non-zero”)?</p>
</li>
<li>
<p>(I left it as <code>unsafe fn alloc</code> just to keep the API uniform with
<code>dealloc</code> and <code>realloc</code>.)</p>
</li>
</ul>
</li>
<li>
<p>Should <code>Allocator::realloc</code> not require that <code>new_layout.align()</code>
evenly divide <code>layout.align()</code>? In particular, it is not too
expensive to check if the two layouts are not compatible, and fall
back on <code>alloc</code>/<code>dealloc</code> in that case.</p>
</li>
<li>
<p>Should <code>Allocator</code> not provide unchecked variants on <code>fn alloc</code>,
<code>fn realloc</code>, et cetera? (To me it seems having them does no harm,
apart from potentially misleading clients who do not read the
documentation about what scenarios yield undefined behavior.</p>
<ul>
<li>Another option here would be to provide a <code>trait UncheckedAllocator: Allocator</code> that carries the unchecked
methods, so that clients who require such micro-optimized paths
can ensure that their clients actually pass them an
implementation that has the checks omitted.</li>
</ul>
</li>
<li>
<p>On the flip-side of the previous bullet, should <code>Allocator</code> provide
<code>fn alloc_one_unchecked</code> and <code>fn dealloc_one_unchecked</code> ?
I think the only check that such variants would elide would be that
<code>T</code> is not zero-sized; I’m not sure that’s worth it.
(But the resulting uniformity of the whole API might shift the
balance to “worth it”.)</p>
</li>
<li>
<p>Should the precondition of allocation methods be loosened to
accept zero-sized types?</p>
<p>Right now, there is a requirement that the allocation requests
denote non-zero sized types (this requirement is encoded in two
ways: for <code>Layout</code>-consuming methods like <code>alloc</code>, it is enforced
via the invariant that the <code>Size</code> is a <code>NonZero</code>, and this is
enforced by checks in the <code>Layout</code> construction code; for the
convenience methods like <code>alloc_one</code>, they will return <code>Err</code> if the
allocation request is zero-sized).</p>
<p>The main motivation for this restriction is some underlying system
allocators, like <code>jemalloc</code>, explicitly disallow zero-sized
inputs. Therefore, to remove all unnecessary control-flow branches
between the client and the underlying allocator, the <code>Allocator</code>
trait is bubbling that restriction up and imposing it onto the
clients, who will presumably enforce this invariant via
container-specific means.</p>
<p>But: pre-existing container types (like <code>Vec&lt;T&gt;</code>) already
<em>allow</em> zero-sized <code>T</code>. Therefore, there is an unfortunate mismatch
between the ideal API those container would prefer for their
allocators and the actual service that this <code>Allocator</code> trait is
providing.</p>
<p>So: Should we lift this precondition of the allocation methods, and allow
zero-sized requests (which might be handled by a global sentinel value, or
by an allocator-specific sentinel value, or via some other means – this
would have to be specified as part of the Allocator API)?</p>
<p>(As a middle ground, we could lift the precondition solely for the convenience
methods like <code>fn alloc_one</code> and <code>fn alloc_array</code>; that way, the most low-level
methods like <code>fn alloc</code> would continue to minimize the overhead they add
over the underlying system allocator, while the convenience methods would truly
be convenient.)</p>
</li>
<li>
<p>Should <code>oom</code> be a free-function rather than a method on <code>Allocator</code>?
(The reason I want it on <code>Allocator</code> is so that it can provide feedback
about the allocator’s state at the time of the OOM. Zoxc has argued
on the RFC thread that some forms of static analysis, to prove <code>oom</code> is
never invoked, would prefer it to be a free function.)</p>
</li>
</ul>
<h2 id="unresolved-questions"><a class="header" href="#unresolved-questions">Unresolved questions</a></h2>
<ul>
<li>
<p>Since we cannot do <code>RefCell&lt;Pool&gt;</code> (see FIXME above), what is
our standard recommendation for what to do instead?</p>
</li>
<li>
<p>Should <code>Layout</code> be an associated type of <code>Allocator</code> (see
<a href="#alternatives">alternatives</a> section for discussion).
(In fact, most of the “Variations correspond to potentially
unresolved questions.)</p>
</li>
<li>
<p>Are the type definitions for <code>Size</code>, <code>Capacity</code>, <code>Alignment</code>, and
<code>Address</code> an abuse of the <code>NonZero</code> type? (Or do we just need some
constructor for <code>NonZero</code> that asserts that the input is non-zero)?</p>
</li>
<li>
<p>Do we need <code>Allocator::max_size</code> and <code>Allocator::max_align</code> ?</p>
</li>
<li>
<p>Should default impl of <code>Allocator::max_align</code> return <code>None</code>, or is
there more suitable default? (perhaps e.g. <code>PLATFORM_PAGE_SIZE</code>?)</p>
<p>The previous allocator documentation provided by Daniel Micay
suggest that we should specify that behavior unspecified if
allocation is too large, but if that is the case, then we should
definitely provide some way to <em>observe</em> that threshold.)</p>
<p>From what I can tell, we cannot currently assume that all
low-level allocators will behave well for large alignments.
See https://github.com/rust-lang/rust/issues/30170</p>
</li>
<li>
<p>Should <code>Allocator::oom</code> also take a <code>std::fmt::Arguments&lt;'a&gt;</code> parameter
so that clients can feed in context-specific information that is not
part of the original input <code>Layout</code> argument? (I have not done this
mainly because I do not want to introduce a dependency on <code>libstd</code>.)</p>
</li>
</ul>
<h2 id="change-history"><a class="header" href="#change-history">Change History</a></h2>
<ul>
<li>
<p>Changed <code>fn usable_size</code> to return <code>(l, m)</code> rather than just <code>m</code>.</p>
</li>
<li>
<p>Removed <code>fn is_transient</code> from <code>trait AllocError</code>, and removed discussion
of transient errors from the API.</p>
</li>
<li>
<p>Made <code>fn dealloc</code> method infallible (i.e. removed its <code>Result</code> return type).</p>
</li>
<li>
<p>Alpha-renamed <code>alloc::Kind</code> type to <code>alloc::Layout</code>, and made it non-<code>Copy</code>.</p>
</li>
<li>
<p>Revised <code>fn oom</code> method to take the <code>Self::Error</code> as an input (so that the
allocator can, indirectly, feed itself information about what went wrong).</p>
</li>
<li>
<p>Removed associated <code>Error</code> type from <code>Allocator</code> trait; all methods now use <code>AllocErr</code>
for error type. Removed <code>AllocError</code> trait and <code>MemoryExhausted</code> error.</p>
</li>
<li>
<p>Removed <code>fn max_size</code> and <code>fn max_align</code> methods; we can put them back later if
someone demonstrates a need for them.</p>
</li>
<li>
<p>Added <code>fn realloc_in_place</code>.</p>
</li>
<li>
<p>Removed uses of <code>NonZero</code>. Made <code>Layout</code> able to represent zero-sized layouts.
A given <code>Allocator</code> may or may not support zero-sized layouts.</p>
</li>
<li>
<p>Various other API revisions were made during development of
<a href="https://github.com/rust-lang/rust/pull/42313">PR 42313</a>, “allocator integration”. See the <a href="https://doc.rust-lang.org/nightly/alloc/allocator/trait.Alloc.html">nightly API docs</a>
rather than using RFC document as a sole reference.</p>
</li>
</ul>
<h2 id="appendices"><a class="header" href="#appendices">Appendices</a></h2>
<h3 id="bibliography"><a class="header" href="#bibliography">Bibliography</a></h3>
<h4 id="rfc-pull-request-39-allocator-trait"><a class="header" href="#rfc-pull-request-39-allocator-trait">RFC Pull Request #39: Allocator trait</a></h4>
<p>Daniel Micay, 2014. RFC: Allocator trait. https://github.com/thestinger/rfcs/blob/ad4cdc2662cc3d29c3ee40ae5abbef599c336c66/active/0000-allocator-trait.md</p>
<h4 id="rfc-pull-request-244-allocator-rfc-take-ii"><a class="header" href="#rfc-pull-request-244-allocator-rfc-take-ii">RFC Pull Request #244: Allocator RFC, take II</a></h4>
<p>Felix Klock, 2014, Allocator RFC, take II, https://github.com/pnkfelix/rfcs/blob/d3c6068e823f495ee241caa05d4782b16e5ef5d8/active/0000-allocator.md</p>
<h4 id="dynamic-storage-allocation-a-survey-and-critical-review"><a class="header" href="#dynamic-storage-allocation-a-survey-and-critical-review">Dynamic Storage Allocation: A Survey and Critical Review</a></h4>
<p>Paul R. Wilson, Mark S. Johnstone, Michael Neely, and David Boles, 1995. <a href="https://parasol.tamu.edu/~rwerger/Courses/689/spring2002/day-3-ParMemAlloc/papers/wilson95dynamic.pdf">Dynamic Storage Allocation: A Survey and Critical Review</a> ftp://ftp.cs.utexas.edu/pub/garbage/allocsrv.ps .  Slightly modified version appears in Proceedings of 1995 International Workshop on Memory Management (IWMM ’95), Kinross, Scotland, UK, September 27–29, 1995 Springer Verlag LNCS</p>
<h4 id="reconsidering-custom-memory-allocation"><a class="header" href="#reconsidering-custom-memory-allocation">Reconsidering custom memory allocation</a></h4>
<p>Emery D. Berger, Benjamin G. Zorn, and Kathryn S. McKinley. 2002. <a href="http://dl.acm.org/citation.cfm?id=582421">Reconsidering custom memory allocation</a>. In Proceedings of the 17th ACM SIGPLAN conference on Object-oriented programming, systems, languages, and applications (OOPSLA ’02).</p>
<h4 id="the-memory-fragmentation-problem-solved"><a class="header" href="#the-memory-fragmentation-problem-solved">The memory fragmentation problem: solved?</a></h4>
<p>Mark S. Johnstone and Paul R. Wilson. 1998. <a href="http://dl.acm.org/citation.cfm?id=286864">The memory fragmentation problem: solved?</a>. In Proceedings of the 1st international symposium on Memory management (ISMM ’98).</p>
<h4 id="eastl-electronic-arts-standard-template-library"><a class="header" href="#eastl-electronic-arts-standard-template-library">EASTL: Electronic Arts Standard Template Library</a></h4>
<p>Paul Pedriana. 2007. <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html">EASTL</a> – Electronic Arts Standard Template Library. Document number: N2271=07-0131</p>
<h4 id="towards-a-better-allocator-model"><a class="header" href="#towards-a-better-allocator-model">Towards a Better Allocator Model</a></h4>
<p>Pablo Halpern. 2005. <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2005/n1850.pdf">Towards a Better Allocator Model</a>. Document number: N1850=05-0110</p>
<h4 id="various-allocators"><a class="header" href="#various-allocators">Various allocators</a></h4>
<p><a href="http://www.canonware.com/jemalloc/">jemalloc</a>, <a href="http://goog-perftools.sourceforge.net/doc/tcmalloc.html">tcmalloc</a>, <a href="http://www.hoard.org/">Hoard</a></p>
<h3 id="ascii-art-version-of-allocator-message-sequence-chart"><a class="header" href="#ascii-art-version-of-allocator-message-sequence-chart">ASCII art version of Allocator message sequence chart</a></h3>
<p>This is an ASCII art version of the SVG message sequence chart
from the <a href="#semantics-of-allocators-and-their-memory-blocks">semantics of allocators</a> section.</p>
<pre><code>Program             Vec&lt;Widget, &amp;mut Allocator&gt;         Allocator
  ||
  ||
   +--------------- create allocator -------------------&gt; ** (an allocator is born)
  *| &lt;------------ return allocator A ---------------------+
  ||                                                       |
  ||                                                       |
   +- create vec w/ &amp;mut A -&gt; ** (a vec is born)           |
  *| &lt;------return vec V ------+                           |
  ||                           |                           |
   *------- push W_1 -------&gt; *|                           |
   |                          ||                           |
   |                          ||                           |
   |                           +--- allocate W array ---&gt; *|
   |                           |                          ||
   |                           |                          ||
   |                           |                           +---- (request system memory if necessary)
   |                           |                          *| &lt;-- ...
   |                           |                          ||
   |                          *| &lt;--- return *W block -----+
   |                          ||                           |
   |                          ||                           |
  *| &lt;------- (return) -------+|                           |
  ||                           |                           |
   +------- push W_2 --------&gt;+|                           |
   |                          ||                           |
  *| &lt;------- (return) -------+|                           |
  ||                           |                           |
   +------- push W_3 --------&gt;+|                           |
   |                          ||                           |
  *| &lt;------- (return) -------+|                           |
  ||                           |                           |
   +------- push W_4 --------&gt;+|                           |
   |                          ||                           |
  *| &lt;------- (return) -------+|                           |
  ||                           |                           |
   +------- push W_5 --------&gt;+|                           |
   |                          ||                           |
   |                           +---- realloc W array ---&gt; *|
   |                           |                          ||
   |                           |                          ||
   |                           |                           +---- (request system memory if necessary)
   |                           |                          *| &lt;-- ...
   |                           |                          ||
   |                          *| &lt;--- return *W block -----+
  *| &lt;------- (return) -------+|                           |
  ||                           |                           |
  ||                           |                           |
   .                           .                           .
   .                           .                           .
   .                           .                           .
  ||                           |                           |
  ||                           |                           |
  || (end of Vec scope)        |                           |
  ||                           |                           |
   +------ drop Vec --------&gt; *|                           |
   |                          || (Vec destructor)          |
   |                          ||                           |
   |                           +---- dealloc W array --&gt;  *|
   |                           |                          ||
   |                           |                           +---- (potentially return system memory)
   |                           |                          *| &lt;-- ...
   |                           |                          ||
   |                          *| &lt;------- (return) --------+
  *| &lt;------- (return) --------+                           |
  ||                                                       |
  ||                                                       |
  ||                                                       |
  || (end of Allocator scope)                              |
  ||                                                       |
   +------------------ drop Allocator ------------------&gt; *|
   |                                                      ||
   |                                                      |+---- (return any remaining associated memory)
   |                                                      *| &lt;-- ...
   |                                                      ||
  *| &lt;------------------ (return) -------------------------+
  ||
  ||
   .
   .
   .
</code></pre>
<h3 id="transcribed-source-for-allocator-trait-api"><a class="header" href="#transcribed-source-for-allocator-trait-api">Transcribed Source for Allocator trait API</a></h3>
<p>Here is the whole source file for my prototype allocator API,
sub-divided roughly accordingly to functionality.</p>
<p>(We start with the usual boilerplate…)</p>
<pre><code class="language-rust">// Copyright 2015 The Rust Project Developers. See the COPYRIGHT
// file at the top-level directory of this distribution and at
// http://rust-lang.org/COPYRIGHT.
//
// Licensed under the Apache License, Version 2.0 &lt;LICENSE-APACHE or
// http://www.apache.org/licenses/LICENSE-2.0&gt; or the MIT license
// &lt;LICENSE-MIT or http://opensource.org/licenses/MIT&gt;, at your
// option. This file may not be copied, modified, or distributed
// except according to those terms.

#![unstable(feature = "allocator_api",
            reason = "the precise API and guarantees it provides may be tweaked \
                      slightly, especially to possibly take into account the \
                      types being stored to make room for a future \
                      tracing garbage collector",
            issue = "27700")]

use core::cmp;
use core::mem;
use core::nonzero::NonZero;
use core::ptr::{self, Unique};
</code></pre>
<h4 id="type-aliases"><a class="header" href="#type-aliases">Type Aliases</a></h4>
<pre><code class="language-rust">pub type Size = usize;
pub type Capacity = usize;
pub type Alignment = usize;

pub type Address = *mut u8;

/// Represents the combination of a starting address and
/// a total capacity of the returned block.
pub struct Excess(Address, Capacity);

fn size_align&lt;T&gt;() -&gt; (usize, usize) {
    (mem::size_of::&lt;T&gt;(), mem::align_of::&lt;T&gt;())
}
</code></pre>
<h4 id="layout-api"><a class="header" href="#layout-api">Layout API</a></h4>
<pre><code class="language-rust">/// Category for a memory record.
///
/// An instance of `Layout` describes a particular layout of memory.
/// You build a `Layout` up as an input to give to an allocator.
///
/// All layouts have an associated non-negative size and positive alignment.
#[derive(Clone, Debug, PartialEq, Eq)]
pub struct Layout {
    // size of the requested block of memory, measured in bytes.
    size: Size,
    // alignment of the requested block of memory, measured in bytes.
    // we ensure that this is always a power-of-two, because API's
    ///like `posix_memalign` require it and it is a reasonable
    // constraint to impose on Layout constructors.
    //
    // (However, we do not analogously require `align &gt;= sizeof(void*)`,
    //  even though that is *also* a requirement of `posix_memalign`.)
    align: Alignment,
}


// FIXME: audit default implementations for overflow errors,
// (potentially switching to overflowing_add and
//  overflowing_mul as necessary).

impl Layout {
    // (private constructor)
    fn from_size_align(size: usize, align: usize) -&gt; Layout {
        assert!(align.is_power_of_two());
        assert!(align &gt; 0);
        Layout { size: size, align: align }
    }

    /// The minimum size in bytes for a memory block of this layout.
    pub fn size(&amp;self) -&gt; usize { self.size }

    /// The minimum byte alignment for a memory block of this layout.
    pub fn align(&amp;self) -&gt; usize { self.align }

    /// Constructs a `Layout` suitable for holding a value of type `T`.
    pub fn new&lt;T&gt;() -&gt; Self {
        let (size, align) = size_align::&lt;T&gt;();
        Layout::from_size_align(size, align)
    }

    /// Produces layout describing a record that could be used to
    /// allocate backing structure for `T` (which could be a trait
    /// or other unsized type like a slice).
    pub fn for_value&lt;T: ?Sized&gt;(t: &amp;T) -&gt; Self {
        let (size, align) = (mem::size_of_val(t), mem::align_of_val(t));
        Layout::from_size_align(size, align)
    }

    /// Creates a layout describing the record that can hold a value
    /// of the same layout as `self`, but that also is aligned to
    /// alignment `align` (measured in bytes).
    ///
    /// If `self` already meets the prescribed alignment, then returns
    /// `self`.
    ///
    /// Note that this method does not add any padding to the overall
    /// size, regardless of whether the returned layout has a different
    /// alignment. In other words, if `K` has size 16, `K.align_to(32)`
    /// will *still* have size 16.
    pub fn align_to(&amp;self, align: Alignment) -&gt; Self {
        if align &gt; self.align {
            let pow2_align = align.checked_next_power_of_two().unwrap();
            debug_assert!(pow2_align &gt; 0); // (this follows from self.align &gt; 0...)
            Layout { align: pow2_align,
                     ..*self }
        } else {
            self.clone()
        }
    }

    /// Returns the amount of padding we must insert after `self`
    /// to ensure that the following address will satisfy `align`
    /// (measured in bytes).
    ///
    /// Behavior undefined if `align` is not a power-of-two.
    ///
    /// Note that in practice, this is only useable if `align &lt;=
    /// self.align` otherwise, the amount of inserted padding would
    /// need to depend on the particular starting address for the
    /// whole record, because `self.align` would not provide
    /// sufficient constraint.
    pub fn padding_needed_for(&amp;self, align: Alignment) -&gt; usize {
        debug_assert!(align &lt;= self.align());
        let len = self.size();
        let len_rounded_up = (len + align - 1) &amp; !(align - 1);
        return len_rounded_up - len;
    }

    /// Creates a layout describing the record for `n` instances of
    /// `self`, with a suitable amount of padding between each to
    /// ensure that each instance is given its requested size and
    /// alignment. On success, returns `(k, offs)` where `k` is the
    /// layout of the array and `offs` is the distance between the start
    /// of each element in the array.
    ///
    /// On arithmetic overflow, returns `None`.
    pub fn repeat(&amp;self, n: usize) -&gt; Option&lt;(Self, usize)&gt; {
        let padded_size = match self.size.checked_add(self.padding_needed_for(self.align)) {
            None =&gt; return None,
            Some(padded_size) =&gt; padded_size,
        };
        let alloc_size = match padded_size.checked_mul(n) {
            None =&gt; return None,
            Some(alloc_size) =&gt; alloc_size,
        };
        Some((Layout::from_size_align(alloc_size, self.align), padded_size))
    }

    /// Creates a layout describing the record for `self` followed by
    /// `next`, including any necessary padding to ensure that `next`
    /// will be properly aligned. Note that the result layout will
    /// satisfy the alignment properties of both `self` and `next`.
    ///
    /// Returns `Some((k, offset))`, where `k` is layout of the concatenated
    /// record and `offset` is the relative location, in bytes, of the
    /// start of the `next` embedded witnin the concatenated record
    /// (assuming that the record itself starts at offset 0).
    ///
    /// On arithmetic overflow, returns `None`.
    pub fn extend(&amp;self, next: Self) -&gt; Option&lt;(Self, usize)&gt; {
        let new_align = cmp::max(self.align, next.align);
        let realigned = Layout { align: new_align, ..*self };
        let pad = realigned.padding_needed_for(new_align);
        let offset = self.size() + pad;
        let new_size = offset + next.size();
        Some((Layout::from_size_align(new_size, new_align), offset))
    }

    /// Creates a layout describing the record for `n` instances of
    /// `self`, with no padding between each instance.
    ///
    /// On arithmetic overflow, returns `None`.
    pub fn repeat_packed(&amp;self, n: usize) -&gt; Option&lt;Self&gt; {
        let scaled = match self.size().checked_mul(n) {
            None =&gt; return None,
            Some(scaled) =&gt; scaled,
        };
        let size = { assert!(scaled &gt; 0); scaled };
        Some(Layout { size: size, align: self.align })
    }

    /// Creates a layout describing the record for `self` followed by
    /// `next` with no additional padding between the two. Since no
    /// padding is inserted, the alignment of `next` is irrelevant,
    /// and is not incorporated *at all* into the resulting layout.
    ///
    /// Returns `(k, offset)`, where `k` is layout of the concatenated
    /// record and `offset` is the relative location, in bytes, of the
    /// start of the `next` embedded witnin the concatenated record
    /// (assuming that the record itself starts at offset 0).
    ///
    /// (The `offset` is always the same as `self.size()`; we use this
    ///  signature out of convenience in matching the signature of
    ///  `fn extend`.)
    ///
    /// On arithmetic overflow, returns `None`.
    pub fn extend_packed(&amp;self, next: Self) -&gt; Option&lt;(Self, usize)&gt; {
        let new_size = match self.size().checked_add(next.size()) {
            None =&gt; return None,
            Some(new_size) =&gt; new_size,
        };
        Some((Layout { size: new_size, ..*self }, self.size()))
    }

    // Below family of methods *assume* inputs are pre- or
    // post-validated in some manner. (The implementations here
    ///do indirectly validate, but that is not part of their
    /// specification.)
    //
    // Since invalid inputs could yield ill-formed layouts, these
    // methods are `unsafe`.

    /// Creates layout describing the record for a single instance of `T`.
    pub unsafe fn new_unchecked&lt;T&gt;() -&gt; Self {
        let (size, align) = size_align::&lt;T&gt;();
        Layout::from_size_align(size, align)
    }


    /// Creates a layout describing the record for `self` followed by
    /// `next`, including any necessary padding to ensure that `next`
    /// will be properly aligned. Note that the result layout will
    /// satisfy the alignment properties of both `self` and `next`.
    ///
    /// Returns `(k, offset)`, where `k` is layout of the concatenated
    /// record and `offset` is the relative location, in bytes, of the
    /// start of the `next` embedded witnin the concatenated record
    /// (assuming that the record itself starts at offset 0).
    ///
    /// Requires no arithmetic overflow from inputs.
    pub unsafe fn extend_unchecked(&amp;self, next: Self) -&gt; (Self, usize) {
        self.extend(next).unwrap()
    }

    /// Creates a layout describing the record for `n` instances of
    /// `self`, with a suitable amount of padding between each.
    ///
    /// Requires non-zero `n` and no arithmetic overflow from inputs.
    /// (See also the `fn array` checked variant.)
    pub unsafe fn repeat_unchecked(&amp;self, n: usize) -&gt; (Self, usize) {
        self.repeat(n).unwrap()
    }

    /// Creates a layout describing the record for `n` instances of
    /// `self`, with no padding between each instance.
    ///
    /// Requires non-zero `n` and no arithmetic overflow from inputs.
    /// (See also the `fn array_packed` checked variant.)
    pub unsafe fn repeat_packed_unchecked(&amp;self, n: usize) -&gt; Self {
        self.repeat_packed(n).unwrap()
    }

    /// Creates a layout describing the record for `self` followed by
    /// `next` with no additional padding between the two. Since no
    /// padding is inserted, the alignment of `next` is irrelevant,
    /// and is not incorporated *at all* into the resulting layout.
    ///
    /// Returns `(k, offset)`, where `k` is layout of the concatenated
    /// record and `offset` is the relative location, in bytes, of the
    /// start of the `next` embedded witnin the concatenated record
    /// (assuming that the record itself starts at offset 0).
    ///
    /// (The `offset` is always the same as `self.size()`; we use this
    ///  signature out of convenience in matching the signature of
    ///  `fn extend`.)
    ///
    /// Requires no arithmetic overflow from inputs.
    /// (See also the `fn extend_packed` checked variant.)
    pub unsafe fn extend_packed_unchecked(&amp;self, next: Self) -&gt; (Self, usize) {
        self.extend_packed(next).unwrap()
    }

    /// Creates a layout describing the record for a `[T; n]`.
    ///
    /// On zero `n`, zero-sized `T`, or arithmetic overflow, returns `None`.
    pub fn array&lt;T&gt;(n: usize) -&gt; Option&lt;Self&gt; {
        Layout::new::&lt;T&gt;()
            .repeat(n)
            .map(|(k, offs)| {
                debug_assert!(offs == mem::size_of::&lt;T&gt;());
                k
            })
    }

    /// Creates a layout describing the record for a `[T; n]`.
    ///
    /// Requires nonzero `n`, nonzero-sized `T`, and no arithmetic
    /// overflow; otherwise behavior undefined.
    pub fn array_unchecked&lt;T&gt;(n: usize) -&gt; Self {
        Layout::array::&lt;T&gt;(n).unwrap()
    }

}
</code></pre>
<h4 id="allocerr-api"><a class="header" href="#allocerr-api">AllocErr API</a></h4>
<pre><code class="language-rust">/// The `AllocErr` error specifies whether an allocation failure is
/// specifically due to resource exhaustion or if it is due to
/// something wrong when combining the given input arguments with this
/// allocator.
#[derive(Clone, PartialEq, Eq, Debug)]
pub enum AllocErr {
    /// Error due to hitting some resource limit or otherwise running
    /// out of memory. This condition strongly implies that *some*
    /// series of deallocations would allow a subsequent reissuing of
    /// the original allocation request to succeed.
    Exhausted { request: Layout },

    /// Error due to allocator being fundamentally incapable of
    /// satisfying the original request. This condition implies that
    /// such an allocation request will never succeed on the given
    /// allocator, regardless of environment, memory pressure, or
    /// other contextual conditions.
    ///
    /// For example, an allocator that does not support zero-sized
    /// blocks can return this error variant.
    Unsupported { details: &amp;'static str },
}

impl AllocErr {
    pub fn invalid_input(details: &amp;'static str) -&gt; Self {
        AllocErr::Unsupported { details: details }
    }
    pub fn is_memory_exhausted(&amp;self) -&gt; bool {
        if let AllocErr::Exhausted { .. } = *self { true } else { false }
    }
    pub fn is_request_unsupported(&amp;self) -&gt; bool {
        if let AllocErr::Unsupported { .. } = *self { true } else { false }
    }
}

/// The `CannotReallocInPlace` error is used when `fn realloc_in_place`
/// was unable to reuse the given memory block for a requested layout.
#[derive(Clone, PartialEq, Eq, Debug)]
pub struct CannotReallocInPlace;
</code></pre>
<h4 id="allocator-trait-header"><a class="header" href="#allocator-trait-header">Allocator trait header</a></h4>
<pre><code class="language-rust">/// An implementation of `Allocator` can allocate, reallocate, and
/// deallocate arbitrary blocks of data described via `Layout`.
///
/// Some of the methods require that a layout *fit* a memory block.
/// What it means for a layout to "fit" a memory block means is that
/// the following two conditions must hold:
///
/// 1. The block's starting address must be aligned to `layout.align()`.
///
/// 2. The block's size must fall in the range `[use_min, use_max]`, where:
///
///    * `use_min` is `self.usable_size(layout).0`, and
///
///    * `use_max` is the capacity that was (or would have been)
///      returned when (if) the block was allocated via a call to
///      `alloc_excess` or `realloc_excess`.
///
/// Note that:
///
///  * the size of the layout most recently used to allocate the block
///    is guaranteed to be in the range `[use_min, use_max]`, and
///
///  * a lower-bound on `use_max` can be safely approximated by a call to
///    `usable_size`.
///
pub unsafe trait Allocator {
</code></pre>
<h4 id="allocator-core-alloc-and-dealloc"><a class="header" href="#allocator-core-alloc-and-dealloc">Allocator core alloc and dealloc</a></h4>
<pre><code class="language-rust">    /// Returns a pointer suitable for holding data described by
    /// `layout`, meeting its size and alignment guarantees.
    ///
    /// The returned block of storage may or may not have its contents
    /// initialized. (Extension subtraits might restrict this
    /// behavior, e.g. to ensure initialization.)
    ///
    /// Returning `Err` indicates that either memory is exhausted or `layout` does
    /// not meet allocator's size or alignment constraints.
    ///
    /// Implementations are encouraged to return `Err` on memory
    /// exhaustion rather than panicking or aborting, but this is
    /// not a strict requirement. (Specifically: it is *legal* to use
    /// this trait to wrap an underlying native allocation library
    /// that aborts on memory exhaustion.)
    unsafe fn alloc(&amp;mut self, layout: Layout) -&gt; Result&lt;Address, AllocErr&gt;;

    /// Deallocate the memory referenced by `ptr`.
    ///
    /// `ptr` must have previously been provided via this allocator,
    /// and `layout` must *fit* the provided block (see above);
    /// otherwise yields undefined behavior.
    unsafe fn dealloc(&amp;mut self, ptr: Address, layout: Layout);

    /// Allocator-specific method for signalling an out-of-memory
    /// condition.
    ///
    /// Implementations of the `oom` method are discouraged from
    /// infinitely regressing in nested calls to `oom`. In
    /// practice this means implementors should eschew allocating,
    /// especially from `self` (directly or indirectly).
    ///
    /// Implementations of this trait's allocation methods are discouraged
    /// from panicking (or aborting) in the event of memory exhaustion;
    /// instead they should return an appropriate error from the
    /// invoked method, and let the client decide whether to invoke
    /// this `oom` method.
    fn oom(&amp;mut self, _: AllocErr) -&gt; ! {
        unsafe { ::core::intrinsics::abort() }
    }</code></pre>
<h4 id="allocator-specific-quantities-and-limits"><a class="header" href="#allocator-specific-quantities-and-limits">Allocator-specific quantities and limits</a></h4>
<pre><code class="language-rust">    // == ALLOCATOR-SPECIFIC QUANTITIES AND LIMITS ==
    // usable_size

    /// Returns bounds on the guaranteed usable size of a successful
    /// allocation created with the specified `layout`.
    ///
    /// In particular, for a given layout `k`, if `usable_size(k)` returns
    /// `(l, m)`, then one can use a block of layout `k` as if it has any
    /// size in the range `[l, m]` (inclusive).
    ///
    /// (All implementors of `fn usable_size` must ensure that
    /// `l &lt;= k.size() &lt;= m`)
    ///
    /// Both the lower- and upper-bounds (`l` and `m` respectively) are
    /// provided: An allocator based on size classes could misbehave
    /// if one attempts to deallocate a block without providing a
    /// correct value for its size (i.e., one within the range `[l, m]`).
    ///
    /// Clients who wish to make use of excess capacity are encouraged
    /// to use the `alloc_excess` and `realloc_excess` instead, as
    /// this method is constrained to conservatively report a value
    /// less than or equal to the minimum capacity for *all possible*
    /// calls to those methods.
    ///
    /// However, for clients that do not wish to track the capacity
    /// returned by `alloc_excess` locally, this method is likely to
    /// produce useful results.
    unsafe fn usable_size(&amp;self, layout: &amp;Layout) -&gt; (Capacity, Capacity) {
        (layout.size(), layout.size())
    }
</code></pre>
<h4 id="allocator-methods-for-memory-reuse"><a class="header" href="#allocator-methods-for-memory-reuse">Allocator methods for memory reuse</a></h4>
<pre><code class="language-rust">    // == METHODS FOR MEMORY REUSE ==
    // realloc. alloc_excess, realloc_excess
    
    /// Returns a pointer suitable for holding data described by
    /// `new_layout`, meeting its size and alignment guarantees. To
    /// accomplish this, this may extend or shrink the allocation
    /// referenced by `ptr` to fit `new_layout`.
    ///
    /// * `ptr` must have previously been provided via this allocator.
    ///
    /// * `layout` must *fit* the `ptr` (see above). (The `new_layout`
    ///   argument need not fit it.)
    ///
    /// Behavior undefined if either of latter two constraints are unmet.
    ///
    /// In addition, `new_layout` should not impose a different alignment
    /// constraint than `layout`. (In other words, `new_layout.align()`
    /// should equal `layout.align()`.)
    /// However, behavior is well-defined (though underspecified) when
    /// this constraint is violated; further discussion below.
    ///
    /// If this returns `Ok`, then ownership of the memory block
    /// referenced by `ptr` has been transferred to this
    /// allocator. The memory may or may not have been freed, and
    /// should be considered unusable (unless of course it was
    /// transferred back to the caller again via the return value of
    /// this method).
    ///
    /// Returns `Err` only if `new_layout` does not meet the allocator's
    /// size and alignment constraints of the allocator or the
    /// alignment of `layout`, or if reallocation otherwise fails. (Note
    /// that did not say "if and only if" -- in particular, an
    /// implementation of this method *can* return `Ok` if
    /// `new_layout.align() != old_layout.align()`; or it can return `Err`
    /// in that scenario, depending on whether this allocator
    /// can dynamically adjust the alignment constraint for the block.)
    ///
    /// If this method returns `Err`, then ownership of the memory
    /// block has not been transferred to this allocator, and the
    /// contents of the memory block are unaltered.
    unsafe fn realloc(&amp;mut self,
                      ptr: Address,
                      layout: Layout,
                      new_layout: Layout) -&gt; Result&lt;Address, AllocErr&gt; {
        let (min, max) = self.usable_size(&amp;layout);
        let s = new_layout.size();
        // All Layout alignments are powers of two, so a comparison
        // suffices here (rather than resorting to a `%` operation).
        if min &lt;= s &amp;&amp; s &lt;= max &amp;&amp; new_layout.align() &lt;= layout.align() {
            return Ok(ptr);
        } else {
            let new_size = new_layout.size();
            let old_size = layout.size();
            let result = self.alloc(new_layout);
            if let Ok(new_ptr) = result {
                ptr::copy(ptr as *const u8, new_ptr, cmp::min(old_size, new_size));
                self.dealloc(ptr, layout);
            }
            result
        }
    }

    /// Behaves like `fn alloc`, but also returns the whole size of
    /// the returned block. For some `layout` inputs, like arrays, this
    /// may include extra storage usable for additional data.
    unsafe fn alloc_excess(&amp;mut self, layout: Layout) -&gt; Result&lt;Excess, AllocErr&gt; {
        let usable_size = self.usable_size(&amp;layout);
        self.alloc(layout).map(|p| Excess(p, usable_size.1))
    }

    /// Behaves like `fn realloc`, but also returns the whole size of
    /// the returned block. For some `layout` inputs, like arrays, this
    /// may include extra storage usable for additional data.
    unsafe fn realloc_excess(&amp;mut self,
                             ptr: Address,
                             layout: Layout,
                             new_layout: Layout) -&gt; Result&lt;Excess, AllocErr&gt; {
        let usable_size = self.usable_size(&amp;new_layout);
        self.realloc(ptr, layout, new_layout)
            .map(|p| Excess(p, usable_size.1))
    }

    /// Attempts to extend the allocation referenced by `ptr` to fit `new_layout`.
    ///
    /// * `ptr` must have previously been provided via this allocator.
    ///
    /// * `layout` must *fit* the `ptr` (see above). (The `new_layout`
    ///   argument need not fit it.)
    ///
    /// Behavior undefined if either of latter two constraints are unmet.
    ///
    /// If this returns `Ok`, then the allocator has asserted that the
    /// memory block referenced by `ptr` now fits `new_layout`, and thus can
    /// be used to carry data of that layout. (The allocator is allowed to
    /// expend effort to accomplish this, such as extending the memory block to
    /// include successor blocks, or virtual memory tricks.)
    ///
    /// If this returns `Err`, then the allocator has made no assertion
    /// about whether the memory block referenced by `ptr` can or cannot
    /// fit `new_layout`.
    ///
    /// In either case, ownership of the memory block referenced by `ptr`
    /// has not been transferred, and the contents of the memory block
    /// are unaltered.
    unsafe fn realloc_in_place(&amp;mut self,
                               ptr: Address,
                               layout: Layout,
                               new_layout: Layout) -&gt; Result&lt;(), CannotReallocInPlace&gt; {
        let (_, _, _) = (ptr, layout, new_layout);
        Err(CannotReallocInPlace)
    }</code></pre>
<h4 id="allocator-convenience-methods-for-common-usage-patterns"><a class="header" href="#allocator-convenience-methods-for-common-usage-patterns">Allocator convenience methods for common usage patterns</a></h4>
<pre><code class="language-rust">    // == COMMON USAGE PATTERNS ==
    // alloc_one, dealloc_one, alloc_array, realloc_array. dealloc_array
    
    /// Allocates a block suitable for holding an instance of `T`.
    ///
    /// Captures a common usage pattern for allocators.
    ///
    /// The returned block is suitable for passing to the
    /// `alloc`/`realloc` methods of this allocator.
    ///
    /// May return `Err` for zero-sized `T`.
    unsafe fn alloc_one&lt;T&gt;(&amp;mut self) -&gt; Result&lt;Unique&lt;T&gt;, AllocErr&gt;
        where Self: Sized {
        let k = Layout::new::&lt;T&gt;();
        if k.size() &gt; 0 {
            self.alloc(k).map(|p|Unique::new(*p as *mut T))
        } else {
            Err(AllocErr::invalid_input("zero-sized type invalid for alloc_one"))
        }
    }

    /// Deallocates a block suitable for holding an instance of `T`.
    ///
    /// The given block must have been produced by this allocator,
    /// and must be suitable for storing a `T` (in terms of alignment
    /// as well as minimum and maximum size); otherwise yields
    /// undefined behavior.
    ///
    /// Captures a common usage pattern for allocators.
    unsafe fn dealloc_one&lt;T&gt;(&amp;mut self, mut ptr: Unique&lt;T&gt;)
        where Self: Sized {
        let raw_ptr = ptr.get_mut() as *mut T as *mut u8;
        self.dealloc(raw_ptr, Layout::new::&lt;T&gt;());
    }

    /// Allocates a block suitable for holding `n` instances of `T`.
    ///
    /// Captures a common usage pattern for allocators.
    ///
    /// The returned block is suitable for passing to the
    /// `alloc`/`realloc` methods of this allocator.
    ///
    /// May return `Err` for zero-sized `T` or `n == 0`.
    ///
    /// Always returns `Err` on arithmetic overflow.
    unsafe fn alloc_array&lt;T&gt;(&amp;mut self, n: usize) -&gt; Result&lt;Unique&lt;T&gt;, AllocErr&gt;
        where Self: Sized {
        match Layout::array::&lt;T&gt;(n) {
            Some(ref layout) if layout.size() &gt; 0 =&gt; {
                self.alloc(layout.clone())
                    .map(|p| {
                        println!("alloc_array layout: {:?} yielded p: {:?}", layout, p);
                        Unique::new(p as *mut T)
                    })
            }
            _ =&gt; Err(AllocErr::invalid_input("invalid layout for alloc_array")),
        }
    }

    /// Reallocates a block previously suitable for holding `n_old`
    /// instances of `T`, returning a block suitable for holding
    /// `n_new` instances of `T`.
    ///
    /// Captures a common usage pattern for allocators.
    ///
    /// The returned block is suitable for passing to the
    /// `alloc`/`realloc` methods of this allocator.
    ///
    /// May return `Err` for zero-sized `T` or `n == 0`.
    ///
    /// Always returns `Err` on arithmetic overflow.
    unsafe fn realloc_array&lt;T&gt;(&amp;mut self,
                               ptr: Unique&lt;T&gt;,
                               n_old: usize,
                               n_new: usize) -&gt; Result&lt;Unique&lt;T&gt;, AllocErr&gt;
        where Self: Sized {
        match (Layout::array::&lt;T&gt;(n_old), Layout::array::&lt;T&gt;(n_new), *ptr) {
            (Some(ref k_old), Some(ref k_new), ptr) if k_old.size() &gt; 0 &amp;&amp; k_new.size() &gt; 0 =&gt; {
                self.realloc(ptr as *mut u8, k_old.clone(), k_new.clone())
                    .map(|p|Unique::new(p as *mut T))
            }
            _ =&gt; {
                Err(AllocErr::invalid_input("invalid layout for realloc_array"))
            }
        }
    }

    /// Deallocates a block suitable for holding `n` instances of `T`.
    ///
    /// Captures a common usage pattern for allocators.
    unsafe fn dealloc_array&lt;T&gt;(&amp;mut self, ptr: Unique&lt;T&gt;, n: usize) -&gt; Result&lt;(), AllocErr&gt;
        where Self: Sized {
        let raw_ptr = *ptr as *mut u8;
        match Layout::array::&lt;T&gt;(n) {
            Some(ref k) if k.size() &gt; 0 =&gt; {
                Ok(self.dealloc(raw_ptr, k.clone()))
            }
            _ =&gt; {
                Err(AllocErr::invalid_input("invalid layout for dealloc_array"))
            }
        }
    }
</code></pre>
<h4 id="allocator-unchecked-method-variants"><a class="header" href="#allocator-unchecked-method-variants">Allocator unchecked method variants</a></h4>
<pre><code class="language-rust">    // UNCHECKED METHOD VARIANTS

    /// Returns a pointer suitable for holding data described by
    /// `layout`, meeting its size and alignment guarantees.
    ///
    /// The returned block of storage may or may not have its contents
    /// initialized. (Extension subtraits might restrict this
    /// behavior, e.g. to ensure initialization.)
    ///
    /// Returns `None` if request unsatisfied.
    ///
    /// Behavior undefined if input does not meet size or alignment
    /// constraints of this allocator.
    unsafe fn alloc_unchecked(&amp;mut self, layout: Layout) -&gt; Option&lt;Address&gt; {
        // (default implementation carries checks, but impl's are free to omit them.)
        self.alloc(layout).ok()
    }

    /// Returns a pointer suitable for holding data described by
    /// `new_layout`, meeting its size and alignment guarantees. To
    /// accomplish this, may extend or shrink the allocation
    /// referenced by `ptr` to fit `new_layout`.
    ////
    /// (In other words, ownership of the memory block associated with
    /// `ptr` is first transferred back to this allocator, but the
    /// same block may or may not be transferred back as the result of
    /// this call.)
    ///
    /// * `ptr` must have previously been provided via this allocator.
    ///
    /// * `layout` must *fit* the `ptr` (see above). (The `new_layout`
    ///   argument need not fit it.)
    ///
    /// * `new_layout` must meet the allocator's size and alignment
    ///    constraints. In addition, `new_layout.align()` must equal
    ///    `layout.align()`. (Note that this is a stronger constraint
    ///    that that imposed by `fn realloc`.)
    ///
    /// Behavior undefined if any of latter three constraints are unmet.
    ///
    /// If this returns `Some`, then the memory block referenced by
    /// `ptr` may have been freed and should be considered unusable.
    ///
    /// Returns `None` if reallocation fails; in this scenario, the
    /// original memory block referenced by `ptr` is unaltered.
    unsafe fn realloc_unchecked(&amp;mut self,
                                ptr: Address,
                                layout: Layout,
                                new_layout: Layout) -&gt; Option&lt;Address&gt; {
        // (default implementation carries checks, but impl's are free to omit them.)
        self.realloc(ptr, layout, new_layout).ok()
    }

    /// Behaves like `fn alloc_unchecked`, but also returns the whole
    /// size of the returned block. 
    unsafe fn alloc_excess_unchecked(&amp;mut self, layout: Layout) -&gt; Option&lt;Excess&gt; {
        self.alloc_excess(layout).ok()
    }

    /// Behaves like `fn realloc_unchecked`, but also returns the
    /// whole size of the returned block.
    unsafe fn realloc_excess_unchecked(&amp;mut self,
                                       ptr: Address,
                                       layout: Layout,
                                       new_layout: Layout) -&gt; Option&lt;Excess&gt; {
        self.realloc_excess(ptr, layout, new_layout).ok()
    }


    /// Allocates a block suitable for holding `n` instances of `T`.
    ///
    /// Captures a common usage pattern for allocators.
    ///
    /// Requires inputs are non-zero and do not cause arithmetic
    /// overflow, and `T` is not zero sized; otherwise yields
    /// undefined behavior.
    unsafe fn alloc_array_unchecked&lt;T&gt;(&amp;mut self, n: usize) -&gt; Option&lt;Unique&lt;T&gt;&gt;
        where Self: Sized {
        let layout = Layout::array_unchecked::&lt;T&gt;(n);
        self.alloc_unchecked(layout).map(|p|Unique::new(*p as *mut T))
    }

    /// Reallocates a block suitable for holding `n_old` instances of `T`,
    /// returning a block suitable for holding `n_new` instances of `T`.
    ///
    /// Captures a common usage pattern for allocators.
    ///
    /// Requires inputs are non-zero and do not cause arithmetic
    /// overflow, and `T` is not zero sized; otherwise yields
    /// undefined behavior.
    unsafe fn realloc_array_unchecked&lt;T&gt;(&amp;mut self,
                                         ptr: Unique&lt;T&gt;,
                                         n_old: usize,
                                         n_new: usize) -&gt; Option&lt;Unique&lt;T&gt;&gt;
        where Self: Sized {
        let (k_old, k_new, ptr) = (Layout::array_unchecked::&lt;T&gt;(n_old),
                                   Layout::array_unchecked::&lt;T&gt;(n_new),
                                   *ptr);
        self.realloc_unchecked(ptr as *mut u8, k_old, k_new)
            .map(|p|Unique::new(*p as *mut T))
    }

    /// Deallocates a block suitable for holding `n` instances of `T`.
    ///
    /// Captures a common usage pattern for allocators.
    ///
    /// Requires inputs are non-zero and do not cause arithmetic
    /// overflow, and `T` is not zero sized; otherwise yields
    /// undefined behavior.
    unsafe fn dealloc_array_unchecked&lt;T&gt;(&amp;mut self, ptr: Unique&lt;T&gt;, n: usize)
        where Self: Sized {
        let layout = Layout::array_unchecked::&lt;T&gt;(n);
        self.dealloc(*ptr as *mut u8, layout);
    }
}</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="1361-cargo-cfg-dependencies.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256 246.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg></span>
                            </a>

                            <a rel="next prefetch" href="1399-repr-pack.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg></span>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="1361-cargo-cfg-dependencies.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256 246.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg></span>
                    </a>

                    <a rel="next prefetch" href="1399-repr-pack.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg></span>
                    </a>
            </nav>

        </div>

        <template id=fa-eye><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></template>
        <template id=fa-eye-slash><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M38.8 5.1C28.4-3.1 13.3-1.2 5.1 9.2S-1.2 34.7 9.2 42.9l592 464c10.4 8.2 25.5 6.3 33.7-4.1s6.3-25.5-4.1-33.7L525.6 386.7c39.6-40.6 66.4-86.1 79.9-118.4c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-68.2 0-125 26.3-169.3 60.8L38.8 5.1zM223.1 149.5C248.6 126.2 282.7 112 320 112c79.5 0 144 64.5 144 144c0 24.9-6.3 48.3-17.4 68.7L408 294.5c5.2-11.8 8-24.8 8-38.5c0-53-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6c0 10.2-2.4 19.8-6.6 28.3l-90.3-70.8zm223.1 298L373 389.9c-16.4 6.5-34.3 10.1-53 10.1c-79.5 0-144-64.5-144-144c0-6.9 .5-13.6 1.4-20.2L83.1 161.5C60.3 191.2 44 220.8 34.5 243.7c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c47.8 0 89.9-12.9 126.2-32.5z"/></svg></span></template>
        <template id=fa-copy><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M502.6 70.63l-61.25-61.25C435.4 3.371 427.2 0 418.7 0H255.1c-35.35 0-64 28.66-64 64l.0195 256C192 355.4 220.7 384 256 384h192c35.2 0 64-28.8 64-64V93.25C512 84.77 508.6 76.63 502.6 70.63zM464 320c0 8.836-7.164 16-16 16H255.1c-8.838 0-16-7.164-16-16L239.1 64.13c0-8.836 7.164-16 16-16h128L384 96c0 17.67 14.33 32 32 32h47.1V320zM272 448c0 8.836-7.164 16-16 16H63.1c-8.838 0-16-7.164-16-16L47.98 192.1c0-8.836 7.164-16 16-16H160V128H63.99c-35.35 0-64 28.65-64 64l.0098 256C.002 483.3 28.66 512 64 512h192c35.2 0 64-28.8 64-64v-32h-47.1L272 448z"/></svg></span></template>
        <template id=fa-play><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M73 39c-14.8-9.1-33.4-9.4-48.5-.9S0 62.6 0 80V432c0 17.4 9.4 33.4 24.5 41.9s33.7 8.1 48.5-.9L361 297c14.3-8.7 23-24.2 23-41s-8.7-32.2-23-41L73 39z"/></svg></span></template>
        <template id=fa-clock-rotate-left><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M75 75L41 41C25.9 25.9 0 36.6 0 57.9V168c0 13.3 10.7 24 24 24H134.1c21.4 0 32.1-25.9 17-41l-30.8-30.8C155 85.5 203 64 256 64c106 0 192 86 192 192s-86 192-192 192c-40.8 0-78.6-12.7-109.7-34.4c-14.5-10.1-34.4-6.6-44.6 7.9s-6.6 34.4 7.9 44.6C151.2 495 201.7 512 256 512c141.4 0 256-114.6 256-256S397.4 0 256 0C185.3 0 121.3 28.7 75 75zm181 53c-13.3 0-24 10.7-24 24V256c0 6.4 2.5 12.5 7 17l72 72c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-65-65V152c0-13.3-10.7-24-24-24z"/></svg></span></template>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr-ef4e11c1.min.js"></script>
        <script src="mark-09e88c2c.min.js"></script>
        <script src="searcher-c2a407aa.js"></script>

        <script src="clipboard-1626706a.min.js"></script>
        <script src="highlight-abc7f01d.js"></script>
        <script src="book-a0b12cfe.js"></script>

        <!-- Custom JS scripts -->



    </div>
    </body>
</html>
